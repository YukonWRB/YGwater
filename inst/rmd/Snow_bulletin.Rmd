---
title: "Yukon Snow Survey \n Bulletin & Water \n Supply Forecast"
#output: html_document
output: 
  word_document:
      reference_docx: style_template2.docx
date: "March 1st 2024"
params:
  year: year
  month: month
  scale: scale
  basins: basins
---

```{r setup, include=FALSE}
# snowBulletin(year = 2023, month = 5, scale = 0.9, basins = c("Upper Yukon", "Teslin", "Central Yukon", "Pelly", "Stewart", "White", "Lower Yukon", "Porcupine", "Peel", "Liard", "Alsek"), save_path = "C:/Users/estewart/Documents/R/Projects/YGwater")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, dpi=300)
con <- YGwater::hydrometConnect()
```


``` {r test, echo=FALSE}
#print(year)
#print(month)
#print(basins)
```


```{r Functions, echo=FALSE}
#### -------------------- A: snow scale/pillow plots ---------------------- ####
snowbullpillow <- function(location, custom_title, year) {
  
  plot <- YGwater::hydrometContinuous(
  location = location,
  parameter = "SWE",
  startDay = paste0(year, "-09-01"),
  endDay = paste0(year, '-07-01'),
  years = year-1,
  returns = "none",
  custom_title = custom_title,
  con = con,
  plot_scale = params$scale, 
  snowbulletin = TRUE
)
plot <- plot + ggplot2::theme(legend.position = "none") #+ 
  #ggplot2::theme(panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 0.5)) #+
  #ggplot2::geom_line(data=plot$data, ggplot2::aes(x=max))


return(plot)

}

#### ------------- B: Function to create basin SWE boxplots --------------- ####
snowbullSWE <- function(loc, basin, year, swe_basins, custom_title) {
  # Subset data
  swe_basin <- swe_basins[swe_basins$location==basin,]
  # Plot
  plot <- hydrometDiscrete(location = loc, parameter = "SWE", startDay = 1, tzone = "MST", years = c(year), title = TRUE, custom_title = custom_title, plot_type = "linedbox", save_path = NULL, discrete_data = swe_basin, con = con, plot_scale = params$scale)
  
  plot <- plot + ggplot2::theme(legend.position = "none")
  
  return(plot)
}


#### ------------- C: Function to create monthly precip plots ------------- ####
snowBullPrecip <- function(tsid, year, scale, custom_title) {
  tab <- DBI::dbGetQuery(con, paste0("SELECT * FROM measurements_continuous WHERE timeseries_id = ", tsid,
                                     " AND datetime >= ", year-40, "-10-01"))
  attr(tab$datetime, "tzone") <- "MST"
  tab$month <- format(tab$datetime, "%m")
  tab$year <- format(tab$datetime, "%Y")
  tab$units <- "mm"

  plot <- hydrometDiscrete(location = NULL, parameter = "Total precipitation",
                 tzone = "MST",
                 years = year-1,#c(params$year),
                 startDay = "2023-10-01", # 275
                 endDay = "2024-05-01", #120
                 title = TRUE, custom_title = custom_title,
                 plot_type = "linedbox", plot_scale = scale,
                 save_path = NULL, discrete_data = tab, con = con)
  plot + ggplot2::theme(legend.position = "none")
}

#### --------------- D: Functions to create CDDF plots -------------------- ####

# Function for calculating CDDF
getCDDF <- function(temps, year) {

  # Function for calculating cddf of dataframe (with all dates of interest)
calcCDDF <- function(temps) {
  cddf <- 0
  temps$cddf <- NA
  for (d in 1:length(temps$value)) {
    t <- temps$value[d]
    # If temperature is NA
    if (is.na(t)) {
      t <- 0
    }
    # If yesterday's cddf is 0 and todays temp is >= 0, keep cddf at 0
    if (cddf==0 & t>=0) {
      cddf <- 0
    } else { 
      cddf <- cddf - t
      if (cddf<0){cddf <- 0}}
    # Set cddf for that day
    temps$cddf[d] <- cddf
  }
return(temps)
} 


# Keep only sept-june data
temps <- temps[format(temps$datetime, "%m") %in% c("09", "10", "11", "12", "01", "02", "03", "04", "05", "06"),]

# Find first and last year 
first_yr <- format(min(temps$datetime), "%Y")
last_yr <- format(max(temps$datetime), "%Y")

# if (last_yr <= year) {
#   last_yr <- year 
# }

cddf <- data.frame()
# Run over every year
for (y in first_yr:last_yr) {
  # Subset data
    tab <- temps[temps$datetime >= paste0(y, '-09-01') 
                 & temps$datetime < paste0(y+1, '-06-14'),]
  # Only calculate if missing less than 10 days, but only for years that are not in the 'years' list
    if (length(tab$datetime) != 0) {
      if (sum(!is.na(tab$value)) >= 276 | format(min(tab$datetime), "%Y") %in% c(year-1)) {
      cddf_y <- calcCDDF(tab)
      cddf <- rbind(cddf, cddf_y)
    }
    }
}

# Rename columns and remove temp
cddf <- cddf[,c("datetime", "cddf")]
colnames(cddf) <- c("datetime", "value")

return(cddf)
}

# Function to create CDDF plots
snowbullCDDF <- function(timeseries_id, custom_title) {
  location <- DBI::dbGetQuery(con, paste0("SELECT datetime, value FROM measurements_continuous WHERE timeseries_id = ", timeseries_id))

  location <- getCDDF(location, params$year)

  plot <- YGwater::hydrometContinuous(parameter= "CDDF", 
                                      startDay = "2023-09-01", 
                                      endDay = "2024-08-31",  
                                      years = c(params$year-1), 
                                      title = TRUE, 
                                      custom_title = custom_title, 
                                      returns = "none", 
                                      allowed_missing = 10, 
                                      plot_scale = params$scale, 
                                      save_path = NULL, 
                                      con = con, 
                                      continuous_data = location, 
                                      snowbulletin = TRUE)
  plot + ggplot2::theme(legend.position = "none") + ggplot2::labs(y="CDDF (\u00B0C days)")
}


#### --------- E: Function to create lake level snow bulletin plots ------- ####

snowbullWater <- function(location, parameter, year, custom_title, scale) {
  flood <- data$flow_level_flood
  tryCatch({
  plot <-
    YGwater::hydrometContinuous(
      location = location,
      parameter = parameter,
      startDay = paste0(year, "-10-01"),
      endDay = paste0(as.character(as.numeric(year) + 1), '-09-30'),
      years = year,
      returns = "none",
      custom_title = custom_title,
      con = con,
      plot_scale = scale * 0.9,
      snowbulletin = TRUE
    )
  #plot <- plot + ggplot2::geom_line(ggplot2::aes(y=zoo::rollmean(max,5, fill=NA)), colour = "#0097A9", size=1) +
   # ggplot2::geom_line(ggplot2::aes(y=zoo::rollmean(min,5, fill=NA)), colour = "#834333", size=1)
  
  if (exists('flood') &
      !is.null(flood) & parameter %in% c("level", "flow")) {
    if (parameter == "level") {
      plot <- plot +
        ggplot2::geom_hline(
          yintercept = dplyr::filter(flood, ID == location)$Flood_level_asl,
          linetype = "dashed",
          color = "red",
          size = 1
        ) +
        ggplot2::annotate(
          "text",
          x = as.POSIXct(paste0(year+1, "-03-25")),
          y = dplyr::filter(flood, ID == location)$Flood_level_asl, #+ (max(plot$data$max)-min(plot$data$min))/20,
          label = "Flood level",
          colour = "red",
          vjust = -0.5
        )
    } else {
      plot <- plot +
        ggplot2::geom_hline(
          yintercept = dplyr::filter(flood, ID == location)$Flood_flow,
          linetype = "dashed",
          color = "red",
          size = 1
        ) +
        ggplot2::annotate(
          "text",
          x = as.POSIXct(paste0(year+1, "-03-25")),
          y = dplyr::filter(flood, ID == location)$Flood_flow,  #+ (max(plot$data$max)-min(plot$data$min)),
          label = "Flood level",
          colour = "red",
          vjust = -0.5
          ) + 
        ggplot2::scale_y_log10()
    }
    
  } else {
    plot <- plot
  }
  
  plot <- plot + ggplot2::theme(legend.position = "none") 
  
  return(plot)
  },
  error = function(e) {
    message("Error when plotting flow data. It is possible that data is missing.")})
  
}



```

```{r SWEbasins, include=FALSE}
# Get SWE data for basins 
swe_basins <- YGwater::SWE_basin(year = params$year,
                                   month = c(3, 4, 5), # c(3)
                                   threshold = 6,
                                   csv = FALSE,
                                   summarise = FALSE)
  # Add datetime to data
  swe_basins$datetime <- paste0(swe_basins$year, "-0", swe_basins$month, "-01")
# Get stats for text
  # Basin % historical median and SWE on target date
  basins_stats <- YGwater::SWE_basin(year = params$year,
                                     month = params$month, # c(3)
                                     threshold = 6,
                                     csv = FALSE,
                                     summarise = TRUE)
  basins_stats <- basins_stats[,c("basin", "swe", "swe_relative")]
  basins_stats$swe <- round(basins_stats$swe, 0)

  # Snow pillow/scale % of historical median
  pillow_stats <- DBI::dbGetQuery(con, paste0("SELECT value, q50, location FROM calculated_daily 
                  INNER JOIN timeseries ON calculated_daily.timeseries_id = timeseries.timeseries_id
                  WHERE calculated_daily.timeseries_id IN (20, 145, 51, 75, 122, 85)
                  AND date = '", params$year, "-0", params$month, "-01'"))
  pillow_stats$perc <- round(pillow_stats$value / pillow_stats$q50 * 100)
  pillow_stats <<- pillow_stats

```
\newpage
  
# PREFACE

The Department of Environment’s Water Resources Branch issues the Yukon Snow Survey Bulletin and Water Supply Forecast three times annually – early March, April and May. The bulletin provides a summary of winter meteorological and streamflow conditions for the Yukon, as well as current snow depth and snow water equivalent observations for 57 locations. This information is used to evaluate the potential for spring flooding caused by both breakup ice jams and large spring snowmelt (freshet) flows. It is important to note that other processes such as summer rain and glacier melt can significantly influence maximum annual water levels in specific Yukon basins. March weather conditions for the Yukon are presented in two maps, one showing temperature anomalies (deviation from climate normals), and another showing precipitation anomalies. Territory-wide snowpack data are presented in a third map showing snow water equivalent (SWE) as a percent of historical median for each station, as well as the basinaveraged estimated SWE for 11 watersheds (or river basins). Complementary meteorological and hydrological data are presented for each basin through a series of five graphs, depending on data availability:

* __Figure A:__ Daily Snow Water Equivalent (SWE) data starting in September at one specific location in the watershed, showing an overview of winter snowpack evolution.
* __Figure B:__ Current, basin-averaged, estimated Snow Water Equivalent (SWE) from snow survey data, compared with historical data, serving as an indicator of potential runoff volumes in the spring (acknowledging that snow sublimation, evapotranspiration, rain and glacier melt also significantly affect runoff).
* __Figure C:__ Monthly winter precipitation (rain and/or snow) compared with historical data, complementing the information presented in Figure B.
* __Figure D:__ Cumulated degree-days of freezing (CDDF, sum of negative daily temperatures) compared with historical data, functioning as an indicator of winter coldness and overall river ice thickness; variables that influence river ice breakup scenarios in the spring.
* __Figure E:__ Current, estimated daily discharge or measured water level, compared with historical data, representing an overview of the watershed hydrological conditions.

For information about the bulletin, snowpack conditions, or streamflow projections please contact waterlevels@yukon.ca

Water Resources Branch, Department of Environment \n
(867) 667-3171, toll free (in Yukon, NWT, Nunavut): 1-800-661-0408, ext. 3171 \n
Fax: 867-667-3195 | Email: waterresources@yukon.ca \n

This bulletin, as well as earlier editions, are available online at: \n
Yukon.ca/snow-survey

ISSN 1705-883X

Reference to this report should be made in the following form: \n
Yukon Snow Survey Bulletin and Water Supply Forecast, `r month.name[params$month]` 1, `r params$year`

© `r month.name[params$month]` `r params$year` \n\n
Water Resources Branch \n
Department of Environment \n
Government of Yukon \n
Box 2703, Whitehorse, Yukon Y1A 2C6



# LEGEND
```{r legend, echo=FALSE, eval=TRUE, fig.align='center', out.width="50%"}
# # Plot A example
# plot <- snowbullpillow(location = "09DB-M1", 
#                custom_title = "A", 
#                year = 2019)
# plot + ggplot2::annotate(geom="text", x=as.POSIXct("2019-02-01", format="%Y-%m-%d"), y=350, label="Maximum", colour='#0097A9')
# 
# # Plot B example
# 
# # Plot D example
# snowbullCDDF(timeseries_id = 500, 
#              custom_title = "D")
# 
# # Plot E example
# snowbullWater(location = "09AB010",
#               parameter = "level",
#               year = 2019,
#               custom_title = "E",
#               scale = 0.9)

lines <- c("Maximum observed value", "Minimum observed value", "Median observed value", "Current year", "Flood level", "25th-75th percentile range of observed values", "Min - max range of observed values")  # Example list of unique legend elements

# Test 1
 ggplot2::ggplot() +
  ggplot2::theme_void() + 
  ggplot2::theme(legend.position = "left") +  # Adjust legend position as needed
  ggplot2::labs(title = "Master Legend") +  # Set legend title
  ggplot2::scale_color_manual(name = "Legend", values = c("#0097A9", "#834333", "#7A9A01", "black", "red", "gray80", "gray90"), labels = lines) +  # Customize legend entries for color
  ggplot2::scale_size_manual(name = "Legend", values = c(1, 1, 1, 1, 1, 7, 7), labels = lines) +  # Customize legend entries for fill
  ggplot2::scale_linetype_manual(name = "Legend", values = c("solid", "solid", "solid", "solid", "dashed", "solid", "solid"), labels = lines) +  # Customize legend entries for shape
  #theme_minimal() +  
   ggplot2::geom_line(ggplot2::aes(x=1, y=1, color= lines, size=lines, linetype=lines)) +
   ggplot2::theme(legend.key.width= ggplot2::unit(2, "cm"))

 
# Test 2  
 lines <- data.frame(
  y = 1:6,
  lty = c("solid", "solid", "solid", "solid", "dashed", "solid"),
  col = c("#0097A9", "#834333", "#7A9A01", "black", "red", "grey"),
  siz = c(1.5, 1.5, 1.5, 1.5, 1.5, 7))

 ggplot2::ggplot(lines, ggplot2::aes(0,y)) +
  #theme_void() + 
  ggplot2::theme(legend.position = "left") +  # Adjust legend position as needed
  ggplot2::labs(title = "Master Legend") +  # Set legend title
  # scale_color_manual(name = "Legend", values = c("#0097A9", "#834333", "#7A9A01", "black", "red", "grey"), labels = lines) +  # Customize legend entries for color
  # scale_size_manual(name = "Legend", values = c(1.5, 1.5, 1.5, 1.5, 1.5, 5), labels = lines) +  # Customize legend entries for fill
  # scale_shape_manual(name = "Legend", values = c("solid", "solid", "solid", "solid", "dashed", "solid"), labels = lines) +  # Customize legend entries for shape
  #theme_minimal() +  
   ggplot2::geom_segment(ggplot2::aes(xend=1, yend=y, color=col, size=siz, shape=lty)) +
  ggplot2::scale_x_continuous(NULL, breaks = NULL) + 
  ggplot2::scale_y_reverse(NULL, breaks = NULL) 
 
 
# Test 3
lnames <- c("Maximum", "Minimum", "Median", "Year", "Flood level", "25th-75th percentile") 
lty <- c("solid", "solid", "solid", "solid", "dashed", "solid")
colty <- c("#0097A9", "#834333", "#7A9A01", "black", "red", "grey")
linetypes <- data.frame(
  y = seq_along(lty),
  lty = lty
) 
ggplot2::ggplot(linetypes, ggplot2::aes(0, y)) + 
  ggplot2::geom_segment(ggplot2::aes(xend = 2, yend = y, linetype = lty, colour = lnames)) + 
  ggplot2::scale_linetype_identity() + 
  ggplot2::scale_color_manual(name = "Legend", values = c("#0097A9", "#834333", "#7A9A01", "black", "red", "grey"), 
                     labels = lines) +
  ggplot2::geom_text(ggplot2::aes(label = lnames), hjust = 0, nudge_y = 0.2) +
  ggplot2::scale_x_continuous(NULL, breaks = NULL) + 
  ggplot2::scale_y_reverse(NULL, breaks = NULL) 
  

``` 

# ACKNOWLEDGEMENTS

The Yukon Snow Survey Bulletin forms part of the Yukon Snow Survey Program administered by the Water Resources
Branch, Department of Environment, Government of Yukon. The Water Resources Branch (WRB) strives for water
stewardship in the Yukon and is committed to responsible and collaborative monitoring to inform the management and
protection of waters.

We are grateful to monitor snow and water across the territories of all fourteen Yukon First Nations and to work in
partnership with many First Nations in different aspects of our work. Though the findings expressed in this report are
based primarily on field observations and relevant scientific data, we acknowledge the deep and longstanding
connection to, and knowledge of snow and water held by, Yukon First Nations.

Gathering snow measurements and data from across our vast territory requires working together with a number of
partners. We’d like to recognize the following agencies/individuals for their significant contributions to the snow survey
bulletin:

* *Data Collection Officer, Natural Resources Conservation Service, United States Department of Agriculture*
* *Meteorologist, Wildland Fire Management, Yukon Department of Community Services, Whitehorse*
* *Officer in Charge, Water Survey of Canada, Whitehorse*
* *Water Management Engineer, Yukon Energy Corporation*
* *Research Technologists, McMaster University*

Agencies cooperating with Environment Yukon in the Snow Survey Program are:

* *B.C. Ministry of Environment, Water Stewardship Division*
* *Parks Canada, Kluane National Park and Reserve*
* *Yukon Department of Highways and Public Works*
* *Yukon Department of Energy Mines and Resources, Compliance Monitoring and Inspections Branch*
* *Yukon Department of Environment, Information Management and Technology Branch*
* *Vuntut Gwitchin First Nation*



# DISCLAIMER AND LIMITATION OF LIABILITY

The User understands and acknowledges that the use of the data is solely at their own risk. The User is solely
responsible for confirming the accuracy, availability, suitability, reliability, usability, completeness or timeliness of the
data.

The User accepts the data “as is” and acknowledges that the Government of Yukon makes no warranties or
representations (express or implied) with respect to the accuracy, availability, suitability, reliability, usability,
completeness or timeliness of the data, including, without limitation, implied warranties for merchantability, fitness for a
particular purpose, and non-infringement.

In consideration of access to the data, the User also agrees that in no event will the Government of Yukon be liable (in
tort or contract) or responsible whatsoever to the User or any other legal entity for the accuracy, availability, suitability,
reliability, usability, completeness or timeliness of the data, including, without limitation, any loss of revenue or profit, or
for direct, indirect, special, incidental, or consequential damages arising from or related to the data.



# YUKON TERRITORY WEATHER AND SNOWPACK CONDITIONS

**October**

**November**

**December**

**January**

**February**

**March**

**April**

**Snowpack**

# YUKON TERRITORY FLOW CONDITIONS AND OUTLOOK


# All basins
```{r All_basins, echo=FALSE, fig.width=10}
# Box plot of SWE of all basins
hydrometDiscrete2 <- function(location=NULL,
                             parameter,
                             startDay = 1,
                             endDay = 365,
                             tzone = "MST",
                             years = NULL,
                             title = TRUE,
                             plot_type = "violin",
                             plot_scale = 1,
                             save_path = NULL,
                             dbPath = "default",
                             discrete_data = NULL)
{
  # # Commented code below is for testing...
  # # location = "08AA-SC01"
  # # parameter = "SWE"
  # # startDay = 1
  # # endDay = 365
  # # tzone = "MST"
  # # years = c(2022)
  # # title = TRUE
  # # plot_scale = 1
  # # plot_type = "boxplot"
  # # save_path = NULL
  # # dbPath ="default"
  # # discrete_data = NULL
  # 
  # #TODO Should give a decent error message if the user requests something that doesn't exist. Station not existing, timeseries not existing, years not available (and where they are), etc.
  # 
  # if (startDay != 1){
  #   startDay <- 1
  #   message("Parameter startDay is not currently in use and has been reset to the default of 1.")
  # }
  # if (endDay != 365){
  #   endDay <- 365
  #   message("Parameter endDay is not currently in use and has been reset to the default of 365.")
  # }
  # 
  # # Checks on input parameters  and other start-up bits------------------
  # if (parameter != "SWE"){
  #   parameter <- tolower(parameter)
  # }
  # 
  # plot_type <- tolower(plot_type)
  # if (!(plot_type %in% c("violin", "boxplot"))){
  #   stop("Parameter 'plot_type' must be one of 'violin' or 'boxplot'")
  # }
  # 
  # if (is.null(years)){
  #   years <- as.numeric(substr(Sys.Date(), 1, 4))
  # } else {
  #   years <- as.numeric(years)
  #   years <- sort(years, decreasing = TRUE)
  #   if (length(years) > 10){
  #     years <- years[1:10]
  #     print("The parameter 'years' can only have up to 10 years. It's been truncated to the first 10 years in the vector.")
  #   }
  # }
  # # Select save path
  # if (!is.null(save_path)){
  #   if (save_path %in% c("Choose", "choose")) {
  #     print("Select the folder where you want this graph saved.")
  #     save_path <- as.character(utils::choose.dir(caption="Select Save Folder"))
  #   }
  # }
  # 
  # 
  # if (is.null(discrete_data)) {
  #   #Connect
  #   con <- hydrometConnect(path = dbPath, silent = TRUE)
  #   on.exit(DBI::dbDisconnect(con))
  # 
  #   # Dealing with start/end dates ----------------------
  #   # Sort out startDay and endDay into actual dates if needed
  #   last_year <- max(years)
  #   leap_list <- (seq(1800, 2100, by = 4))  # Create list of all leap years
  #   tryCatch({
  #     startDay <- as.character(startDay)
  #     startDay <- as.POSIXct(startDay, tz = tzone)
  #     lubridate::year(startDay) <- last_year
  #   }, error = function(e) {
  #     if (last_year %in% leap_list){
  #       if (startDay > 59){
  #         startDay <<- startDay + 1
  #       }
  #     }
  #     startDay <<- as.POSIXct(as.numeric(startDay)*60*60*24, origin = paste0(last_year-1, "-12-31"), tz = "UTC")
  #     startDay <<- lubridate::force_tz(startDay, tzone)
  #   })
  #   tryCatch({
  #     endDay <- as.character(endDay)
  #     endDay <- as.POSIXct(endDay, tz = tzone)
  #     lubridate::year(endDay) <- last_year
  #   }, error = function(e) {
  #     tempStartDay <- lubridate::yday(startDay) #using yday because start is now in proper Date format and needs to be back-converted to yday
  #     if (last_year %in% leap_list){
  #       if (endDay > 59){
  #         endDay <<- endDay + 1
  #       }
  #     }
  #     endDay <<- as.POSIXct(as.numeric(endDay)*60*60*24, origin = paste0(last_year-1, "-12-31 23:59:59"), tz = "UTC")
  #     endDay <<- lubridate::force_tz(endDay, tzone)
  #   })
  #   if (startDay > endDay){ #if the user is wanting a range overlapping the new year
  #     lubridate::year(endDay) <- lubridate::year(endDay)+1
  #     overlaps <- TRUE
  #   } else {
  #     overlaps <- FALSE
  #   }
  # 
  #   day_seq <- seq.POSIXt(startDay, endDay, by = "day")
  # 
  #   #Check for existence of timeseries, then for presence of data within the time range requested.
  #   exists <- DBI::dbGetQuery(con, paste0("SELECT * FROM timeseries WHERE location = '", location, "' AND parameter = '", parameter, "' AND type = 'discrete'"))
  #   if (nrow(exists) == 0){
  #     stop("There is no entry for the location and parameter combination that you specified of discrete data type. If you are trying to graph continuous data use hydrometContinuous.")
  #   } else if (nrow(exists) > 1){
  #     stop("There is more than one entry in the database for the location and parameter that you specified! Please alert the database manager ASAP.")
  #   }
  # 
  # 
  # 
  #   #Find the ts units
  #   units <- DBI::dbGetQuery(con, paste0("SELECT units FROM timeseries WHERE parameter = '", parameter, "' AND location = '", location, "'"))
  # 
  #   # Get the data ---------------------
  #   all_discrete <- DBI::dbGetQuery(con, paste0("SELECT * FROM discrete WHERE location = '", location, "' AND parameter = '", parameter, "' AND sample_date < '", paste0(max(years), substr(endDay, 5, 10)), "'"))
  #   if (nrow(all_discrete) == 0){
  #     stop(paste0("There doesn't appear to be any data for the year and days you specified: this timeseries starts ",  exists$start_datetime_UTC))
  #   }
  #   all_discrete$target_date <- as.Date(all_discrete$target_date)
  #   all_discrete$sample_date <- as.Date(all_discrete$sample_date)
  #   all_discrete$year <- lubridate::year(all_discrete$target_date)
  #   all_discrete$month <- lubridate::month(all_discrete$target_date)
  #   all_discrete$day <- lubridate::day(all_discrete$target_date)
  #   #Separate, modify, and re-bind feb29 days, if any
  #   feb29 <- all_discrete[all_discrete$month == 2 & all_discrete$day == 29, ]
  #   if (nrow(feb29) > 0){
  #     all_discrete <- all_discrete[!(all_discrete$month == 2 & all_discrete$day == 29), ]
  #     feb29$target_date <- feb29$target_date + 1
  #     feb29$month <- 3
  #     feb29$day <- 1
  #     all_discrete <- rbind(all_discrete, feb29)
  #   }
  # 
  #   #Make a fake date
  #   all_discrete$fake_date <- as.Date(gsub("[0-9]{4}", last_year, all_discrete$target_date))
  #   discrete <- data.frame()
  #   for (i in years){
  #     start <- as.Date(paste0(i, substr(startDay, 5, 10)))
  #     end <- as.Date(paste0(i, substr(endDay, 5, 10)))
  #     if (overlaps){
  #       lubridate::year(end) <- lubridate::year(end) +1
  #     }
  #     new_discrete <- all_discrete[all_discrete$target_date >= start & all_discrete$target_date <= end , ]
  #     discrete <- rbind(discrete, new_discrete)
  #   }
  #   if (nrow(discrete) == 0){
  #     stop("There is no data to graph after filtering for your specified year(s) and day range. Try again with different days.")
  #   }
  # 
  # }
  # 
  # if (!is.null(discrete_data)) {
  #   ## Create all_discrete
  #   all_discrete <- discrete_data
  #   # add fake_date
  #   all_discrete$fake_date <- as.Date(paste0(max(years), "-0", all_discrete$month, "-01" ))
  #   ## Create discrete
  #   discrete <- all_discrete %>% dplyr::filter(year %in% years)
  #   ## Give units
  #   units <- unique(discrete$units)
  # 
  # }
  # 
  # #Make the plot --------------------
  #  colours = c("blue", "black", "darkorchid3", "cyan2", "firebrick3", "aquamarine4", "gold1", "chartreuse1", "darkorange", "lightsalmon4")
  # legend_length <- length(years)
  # plot <- ggplot2::ggplot(all_discrete, ggplot2::aes(x = location, y = value, group = location)) +
  #   ggplot2::labs(x = "", y = if (parameter == "SWE") paste0("SWE (", units, ")") else paste0(stringr::str_to_title(parameter), " (", units, ")")) +
  #   ggplot2::theme_classic() +
  #   ggplot2::theme(legend.position = "right", legend.justification = c(0, 0.95), legend.text = ggplot2::element_text(size = 8*plot_scale), legend.title = ggplot2::element_text(size = 10*plot_scale), axis.title.y = ggplot2::element_text(size = 12*plot_scale), axis.text.x = ggplot2::element_text(size = 9*plot_scale), axis.text.y = ggplot2::element_text(size = 9*plot_scale))
  # if (plot_type == "violin") {
  #   plot <- plot +
  #     ggplot2::geom_violin(draw_quantiles = c(0.5), adjust = 0.7, width = 12, alpha = 0.8, fill = "aliceblue", scale = "width") #Using a scale other than "width" may result in issues for locations where there are many "0" values.
  # } else if (plot_type == "boxplot"){
  #   plot <- plot +
  #     ggplot2::geom_boxplot(outlier.shape = 8 , outlier.size = 1.7*plot_scale, color = "black", fill = "aliceblue", varwidth = TRUE)
  # }
  # plot <- plot +
  #   ggplot2::geom_point(data = discrete, mapping = ggplot2::aes(x = location, y = value, colour = as.factor(year), fill = as.factor(year)), size = plot_scale*3.5, shape = 21) +
  #   ggplot2::scale_colour_manual(name = "Year", labels = unique(discrete$year), values = colours[1:legend_length], aesthetics = c("colour", "fill"), na.translate = FALSE, breaks=unique(stats::na.omit(discrete$year))[1:legend_length])
  # 
  # # Wrap things up and return() -----------------------
  # if (title == TRUE){
  #   if (is.null(discrete_data)){
  #     stn_name <- DBI::dbGetQuery(con, paste0("SELECT name FROM locations where location = '", location, "'"))
  #     titl <- paste0("Location ", location, ": ", stn_name)
  #   } else {
  #     if (!is.null(location)) {
  #       titl <- paste0("Location: ", location)}
  #     else {
  #       titl <- paste0("Location: ", unique(all_discrete$location))
  #       }
  # 
  #   }
  # 
  #   plot <- plot +
  #     ggplot2::labs(title=titl) +
  #     ggplot2::theme(plot.title=ggplot2::element_text(hjust=0.05, size=14*plot_scale))
  # }
  # 
  # #Save it if requested
  # if (!is.null(save_path)){
  #   ggplot2::ggsave(filename=paste0(save_path,"/", location, "_", parameter, "_", Sys.Date(), "_", lubridate::hour(as.POSIXct(format(Sys.time()), tz=tzone)), lubridate::minute(as.POSIXct(format(Sys.time()), tz=tzone)), ".png"), plot=plot, height=8, width=12, units="in", device="png", dpi=500)
  # }
  # 
  # return(plot)
}
all_basins <- swe_basins[swe_basins$month == 5,]
plot <- hydrometDiscrete2(location = "all basins", parameter = "SWE", startDay = 1, tzone = "MST", years = params$year, title = FALSE, plot_type = "boxplot", plot_scale = 1, save_path = NULL, discrete_data = all_basins)

``` 

# Upper Yukon river basin (Southern lakes/Whitehorse)

The Upper Yukon River Basin snowpack is _____ average. At Tagish Meteorological Station, Snow Water Equivalent (SWE) is estimated to be **`r pillow_stats[pillow_stats$location=='09AA-M1',]$perc`%** of the historical median (Figure A1), while at Wolf Creek Subalpine Meteorological Station, SWE is estimated to be **`r pillow_stats[pillow_stats$location=='29AB-M3',]$perc`%** of the historical median (Figure A2). The Upper Yukon basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Upper_Yukon',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Upper_Yukon',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Upper Yukon, echo=FALSE}
# Run or don't run following chunks
if ("Upper Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

```{r UpperYukonRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
#r UpperYukonRiver_Snow, echo=FALSE, eval=include, out.width='.49\\linewidth', fig.width=4, fig.height=3,fig.show='hold',fig.align='center'
par(mfrow = c(1, 2))
## A1 Tagish
# Set station ID
station_id <- "09AA-M1"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A1: Tagish Snow Water Equivalent", year = params$year)

## A2 Wolf Creek
# Set station ID
station_id <- "29AB-M3"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A2: Wolf Creek Subalpine Snow Water Equivalent", year = params$year)


``` 

```{r UpperYukon_basin, echo=FALSE, eval=include, out.width="50%", fig.align='center'}
# B
# Plotting 
snowbullSWE(loc= "Upper Yukon", basin = "Upper_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Upper Yukon Basin Monthly Snow Course Data")
``` 

Whitehorse precipitation has been __ from October to February (Figure C). Cumulative winter precipitation is ___ % below/above median on `r month.name[params$month]` 1. Cumulative degreedays of freezing (CDDF) are __ % below/above average, with ___ oC-Days on `r month.name[params$month]` 1 (Figure D), which suggests that the thickness of the ice cover on rivers and lakes of the region is likely ____ than normal.

```{r UpperYukon_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", warnings=FALSE}
par(mfrow = c(1, 2))
# C
snowBullPrecip(663, params$year, params$scale, "C: Whitehorse Monthly Precipitation")

# D
snowbullCDDF(timeseries_id = 484, custom_title = "D: Cumulative Degree-Days of Freezing in Whitehorse")

``` 

The measured water surface elevation (relative to sea level) in Marsh Lake is currently ___ average (Figure E). The current snow and groundwater conditions suggest that water levels will be ___ average this summer. However, weather conditions over the spring and summer will determine the peak water level in Marsh Lake, which typically occurs in late summer in response to peak glacial runoff and large precipitation events. 
Lake Laberge level is currently ___ the historic maximum for this time of year (Figure E2). Lake Laberge follows a similar summer pattern to the upper Southern Lakes and is expected to experience ___ average water levels this summer. 

```{r MarshLake, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E1
# Set station ID
station_id <- "09AB004"
# Plotting
snowbullWater(location = station_id,
              parameter = "level",
              year = params$year-1, #2023, #
              custom_title = "E1: Marsh Lake Water Surface Elevation",
              scale = params$scale)
``` 

```{r LakeLaberge, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E2
# Set station ID
station_id <- "09AB010"
# Plotting
snowbullWater(location = station_id,
              parameter = "level",
              year = params$year-1,
              custom_title = "E2: Lake Laberge Water Surface Elevation",
              scale = params$scale)
``` 

# Teslin river basin

The Teslin River Basin snowpack is ____. The basin-averaged SWE is estimated at **`r basins_stats[basins_stats$basin=='Teslin_Big_Salmon',]$swe_relative * 100`%** of the
historical median, with **`r basins_stats[basins_stats$basin=='Teslin_Big_Salmon',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).


```{r Teslin, echo=FALSE}
if ("Teslin" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

```{r TeslinBigSalmon_basin, echo=FALSE, eval=include, fig.align='center', out.width="50%"}
# B
# Plotting
snowbullSWE(loc= "Teslin - Big Salmon", basin = "Teslin_Big_Salmon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Teslin - Big Salmon Basin Monthly Snow Course Data")
``` 

```{r Teslin_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(665, params$year, params$scale, "C: Teslin Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 532, custom_title = "D: Cumulative Degree-Days of Freezing in Teslin")

``` 

```{r TeslinLake, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09AE002"
# Plotting
snowbullWater(location = station_id,
              parameter = "level",
              year = params$year-1,
              custom_title = "E: Teslin Lake Water Surface Elevation",
              scale = params$scale)
``` 

# Central Yukon river basin (Carmacks area)
```{r Central Yukon, echo=FALSE}
if ("Central Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Central Yukon River Basin snowpack is _____ average. The basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Central_Yukon',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Central_Yukon',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r CentralYukon_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting
snowbullSWE(loc= "Central Yukon", basin = "Central_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Central Yukon Basin Monthly Snow Course Data")
``` 

```{r Carmacks_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(666, params$year, params$scale, "C: Carmacks Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 540, custom_title = "D: Cumulative Degree-Days of Freezing in Carmacks")

``` 

```{r Nordenskiold, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09AH004"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Nordenskiold River Discharge below Rowlinson Creek",
              scale = params$scale)
``` 

# Pelly river basin
```{r Pelly, echo=FALSE}
if ("Pelly" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Pelly River Basin snowpack is _____ average. At Twin Creeks Meteorological Station, Snow Water Equivalent (SWE) is estimated to be **`r pillow_stats[pillow_stats$location=='09BA-M7',]$perc`%** of the historical median (Figure A). The Pelly River basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Pelly',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Pelly',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Pelly_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
## A Twin Creeks
# Set station ID
station_id <- "09BA-M7"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A: Twin Creeks Snow Water Equivalent", year = params$year)

# B
# Plotting 
snowbullSWE(loc= "Pelly", basin = "Pelly",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Pelly Basin Monthly Snow Course Data")

```

```{r Faro_CDDF, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# D
snowbullCDDF(timeseries_id = 500, custom_title = "D: Cumulative Degree-Days of Freezing in Faro")

``` 

```{r PellyRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09BC001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Pelly River Discharge at Pelly Crossing",
              scale = params$scale)
``` 

# Stewart river basin
```{r Stewart, echo=FALSE}
if ("Stewart" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Stewart River Basin snowpack is _____ average. At Withers Lake Meteorological Station, Snow Water Equivalent (SWE) is estimated to be **`r pillow_stats[pillow_stats$location=='09DB-M1',]$perc`%** of the historical median (Figure A). The The Stewart River basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Stewart',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Stewart',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r StewartRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
## A Withers Lake
# Set station ID
station_id <- "09DB-M1"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A: Withers Lake Snow Water Equivalent", year = params$year)
# B
# Plotting 
snowbullSWE(loc= "Stewart", basin = "Stewart",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Stewart Basin Monthly Snow Course Data")

``` 

```{r Mayo_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(668, params$year, params$scale, "C: Mayo Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 548, custom_title = "D: Cumulative Degree-Days of Freezing in Mayo")

``` 

```{r StewartRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09DD003"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Stewart River Discharge at Outlet",
              scale = params$scale)
``` 

# White river basin
```{r White, echo=FALSE}
if ("White" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The White River Basin snowpack is _____ average. The basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='White',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='White',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r White_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting 
snowbullSWE(loc= "White", basin = "White",
            year = params$year, swe_basins = swe_basins, custom_title = "B: White Basin Monthly Snow Course Data")
``` 

```{r WhiteRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09CB001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: White River Discharge at Alaska Highway",
              scale = params$scale)
``` 

# Lower Yukon River basin (Dawson area)
```{r Lower Yukon, echo=FALSE}
if ("Lower Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Lower Yukon River Basin snowpack is _____ average. Established in 2022, the King Solomon Dome Meteorological Station registered Snow Water Equivalent (SWE) at **`r pillow_stats[pillow_stats$location=='09EA-M1',]$perc`%** % of the historical median when compared with the manual snow survey record for that site (Figure A). The Lower Yukon basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Lower_Yukon',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Lower_Yukon',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r LowerYukonRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}

par(mfrow = c(1, 2))

## A King Solomon Dome
# Get this years snow pillow
snow_p <- DBI::dbGetQuery(con, paste0("SELECT date, value FROM calculated_daily ",
                            "WHERE timeseries_id = 85 ",
                            "AND date >= '", params$year-1, "-09-01' ", #params$year
                            "AND date <= '", params$year, "-07-01' ")) #params$year
# Get historical snow survey data
snow_s <- DBI::dbGetQuery(con, paste0("SELECT target_datetime, value FROM measurements_discrete ",
                            "WHERE timeseries_id = 317 "))
  snow_s$fake_date <- as.Date(paste0(params$year, "-", format(snow_s$target_datetime, "%m-%d"))) #params$year
  # Only keep those for March, April, May
  snow_s <- snow_s[format(snow_s$fake_date, "%m-%d") %in% c("03-01", "04-01", "05-01"),]
  # Calculate stats
  snow_s <- snow_s %>%
      dplyr::group_by(.data$fake_date) %>%
      dplyr::summarise(value = min(.data$value), type = "min") %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = max(.data$value), type = "max")) %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = stats::median(.data$value), type = "median"))

ggplot2::ggplot() +
  ggplot2::geom_line(data=snow_p, ggplot2::aes(y=value, x=date)) +
  ggplot2::geom_point(dat=snow_s, ggplot2::aes(y=value, x=fake_date, colour=type))

# B
# Plotting 
snowbullSWE(loc= "Lower Yukon", basin = "Lower_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Lower Yukon Basin Monthly Snow Course Data")

```

```{r Dawson_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(664, params$year, params$scale, "C: Dawson Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 492, custom_title = "D: Cumulative Degree-Days of Freezing in Dawson")

``` 

```{r YukonRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09CD001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Yukon River Discharge at White River",
              scale = params$scale)
``` 

# Porcupine River basin
```{r Porcupine, echo=FALSE}
if ("Porcupine" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Porcupine River Basin snowpack is _____ average. The basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Porcupine',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Porcupine',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Porcupine_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting 
snowbullSWE(loc= "Porcupine", basin = "Porcupine",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Porcupine Basin Monthly Snow Course Data")
``` 

```{r OldCrow_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(671, params$year, params$scale, "C: Old Crow Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 556, custom_title = "D: Cumulative Degree-Days of Freezing in Old Crow")

``` 

```{r PorcupineRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "09FD002"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Porcupine River Discharge at Border",
              scale = params$scale)
``` 

# Peel River basin
```{r Peel, echo=FALSE}
if ("Peel" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Peel River Basin snowpack is _____ average. The basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Peel',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Peel',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Peel_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting 
snowbullSWE(loc= "Peel", basin = "Peel",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Peel Basin Monthly Snow Course Data")
``` 

```{r PeelRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "10MA001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Peel River Discharge",
              scale = params$scale)
``` 

# Liard River basin
```{r Liard, echo=FALSE}
if ("Liard" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Liard River Basin snowpack is _____ average. At Hyland Meteorological Station, Snow Water Equivalent (SWE) is estimated to be **`r pillow_stats[pillow_stats$location=='10AD-M2',]$perc`%** of the historical median (Figure A). The Liard River basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Liard',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Liard',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r LiardRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}

par(mfrow = c(1, 2))

## A Hyland River
# Set station ID
station_id <- "10AD-M2"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A: Hyland River Snow Water Equivalent", year = params$year)

# B
# Plotting 
snowbullSWE(loc= "Liard", basin = "Liard",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Liard Basin Monthly Snow Course Data")

```

```{r WatsonLake_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
par(mfrow = c(1, 2))
# C
snowBullPrecip(667, params$year, params$scale, "C: Watson Lake Monthly Precipitation")
# D
snowbullCDDF(timeseries_id = 508, custom_title = "D: Cumulative Degree-Days of Freezing in Watson Lake")

``` 

```{r LiardRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "10AA001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Liard River Discharge at Upper Liard",
              scale = params$scale)
``` 

# Alsek River basin
```{r Alsek, echo=FALSE}
if ("Alsek" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
``` 

The Alsek River Basin snowpack is _____ average. The basin-averaged SWE is estimated to be **`r basins_stats[basins_stats$basin=='Alsek',]$swe_relative * 100`%** of the historical median, with **`r basins_stats[basins_stats$basin=='Alsek',]$swe`** **mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Alsek_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting 
snowbullSWE(loc= "Alsek", basin = "Alsek",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Alsek Basin Monthly Snow Course Data")
``` 

```{r AlsekRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=3.6}
# E
# Set station ID
station_id <- "08AB001"
# Plotting
snowbullWater(location = station_id,
              parameter = "flow",
              year = params$year-1,
              custom_title = "E: Alsek River Discharge above Bates",
              scale = params$scale)
``` 

# Drainage Basin and Snow Course

```{r table, fig.width=10, results='asis', echo=FALSE}
tabl <- SWE_station(year=params$year, month=params$month, return_missing = TRUE, active = TRUE, source="hydromet")

tabl <- tabl[, c("location_name", "location_id", "sample_date", "depth", "swe", "swe_prevyear", "swe_med", "years", "sub_basin")]

colnames(tabl) <- c("Name", "Number", "Date of Survey", "Snow depth (cm)", "Water content (SWE) (mm)", "Last year SWE (mm)", "Median historical SWE (mm)", "Years of record", "sub_basin")

# Order rows
target <- c("Upper_Yukon", "Teslin_Big_Salmon", "Central_Yukon", "Pelly", "Stewart", "White", "Lower_Yukon", "Porcupine", "Peel", "Liard", "Alsek", "Alaska")
tabl <- tabl %>% dplyr::arrange(factor(sub_basin, levels = target))

## Change basin names
# Add River Basin to names
tabl$sub_basin <- paste0(tabl$sub_basin, " River Basin")
# Replace all _ with space
tabl$sub_basin <- gsub("_", " ", tabl$sub_basin)
tabl$sub_basin <- gsub("Alaska River Basin", "Alaska Snow Courses", tabl$sub_basin)

# Single table using flextable 

flextable::as_grouped_data(tabl, groups = "sub_basin") %>% 
  flextable::as_flextable(hide_grouplabel = TRUE) %>% 
  #flextable::set_header_labels(what = "") %>% 
  flextable::bold(bold = TRUE, part="header") %>% 
  #flextable::align(i = ~ !is.na(sub_basin), align = "left") %>% 
  flextable::align(part="header", align="center") %>%
  flextable::align(align="center", j=c(2:8)) %>%
  flextable::bold(i = ~ !is.na(sub_basin)) %>%
  flextable::bg(bg="#0097A9", part="header") %>%
  #flextable::bg(bg="#77A3A9", part="header") %>%
  flextable::color(color="white", part="header") %>%
  flextable::hline(part="all") %>%
  flextable::vline(part="body") %>% 
  flextable::border_outer() %>% 
  flextable::autofit() %>%
  flextable::width(j="Number", width=1.2) %>%
  flextable::width(j="Date of Survey", width=1.1) %>%
  flextable::width(j=c(4,5,6,7,8), width = 0.8) %>%
  flextable::width(j=c(1), width = 1.7) %>%
  flextable::font(fontname="Nunito Sans", part="all") %>%
  flextable::fontsize(size=11)

# # Multiple tables using kable
# for (b in unique(tabl$sub_basin)) {
#   tbl <- knitr::kable(tabl[tabl$sub_basin == b, c(2:8)], caption = b)
#   print(tbl)
# }
#knitr::kable(tabl, caption = "Caption")

``` 

