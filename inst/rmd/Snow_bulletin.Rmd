---
title: "  \\newline  \\newline  \nYukon Snow Survey  \nBulletin & Water  \nSupply Forecast"
#output: html_document
output: 
  word_document:
      reference_docx: style_template_snowbull.docx

params:
  year: year
  month: month
  scale: scale
  basins: basins
editor_options: 
  markdown: 
    wrap: 72
    
date: "`r paste0(month.name[params$month],' 1, ', params$year)`"
---

```{r setup, include=FALSE}
# snowBulletin(year = 2023, month = 5, scale = 1, basins = c("Upper Yukon", "Teslin", "Central Yukon", "Pelly", "Stewart", "White", "Lower Yukon", "Porcupine", "Peel", "Liard", "Alsek"), save_path = "C:/Users/estewart/Documents/R/Projects/YGwater")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, dpi=300)
con <- YGwater::hydrometConnect()
knitr::include_graphics
fig.height_half <- 3.0
fig.height_full <- 2.8

```

```{r test, echo=FALSE}
#print(year)
#print(month)
#print(basins)
```

```{r Functions, echo=FALSE}
#### -------------------- A: snow scale/pillow plots ---------------------- ####
snowbullpillow <- function(location, custom_title, year) {
  
  plot <- YGwater::hydrometContinuous(
  location = location,
  parameter = "SWE",
  startDay = paste0(year, "-09-01"),
  endDay = paste0(year, '-07-01'),
  years = year-1,
  returns = "none",
  custom_title = custom_title,
  con = con,
  plot_scale = params$scale, 
  snowbulletin = TRUE
)
plot <- plot + ggplot2::theme(legend.position = "none") #+ 
  #ggplot2::theme(panel.border = ggplot2::element_rect(color = "black", fill = NA, size = 0.5)) #+
  #ggplot2::geom_line(data=plot$data, ggplot2::aes(x=max))


return(plot)

}

#### ------------- B: Function to create basin SWE boxplots --------------- ####
snowbullSWE <- function(loc, basin, year, swe_basins, custom_title) {
  # Subset data
  swe_basin <- swe_basins[swe_basins$location==basin,]
  # Plot
  plot <- hydrometDiscrete(location = loc, parameter = "SWE", startDay = 1, tzone = "MST", years = c(year), title = TRUE, custom_title = custom_title, plot_type = "linedbox", save_path = NULL, discrete_data = swe_basin, con = con, plot_scale = params$scale)
  
  plot <- plot + ggplot2::theme(legend.position = "none")
  
  return(plot)
}


#### ------------- C: Function to create monthly precip plots ------------- ####
snowBullPrecip <- function(tsid, year, scale, custom_title) {
  tab <- DBI::dbGetQuery(con, paste0("SELECT * FROM measurements_continuous WHERE timeseries_id = ", tsid,
                                     " AND datetime >= '", year-40, "-10-01'"))
  attr(tab$datetime, "tzone") <- "MST"
  tab$month <- format(tab$datetime, "%m")
  tab$year <- format(tab$datetime, "%Y")
  tab$units <- "mm"

  plot <- hydrometDiscrete(location = NULL, parameter = "Total precipitation",
                 tzone = "MST",
                 years = year-1,#c(params$year),
                 startDay = "2023-10-01", # 275
                 endDay = "2024-05-01", #120
                 title = TRUE, custom_title = custom_title,
                 plot_type = "linedbox", plot_scale = scale,
                 save_path = NULL, discrete_data = tab, con = con)
  plot <- plot + ggplot2::theme(legend.position = "none")

  # Calculate stats (% above/below median of cumulative winter precip)
  # Cumulative median / value on date
  stats_c <- round(sum(plot$plot_env$discrete[plot$plot_env$discrete$month <= params$month | 
                                            plot$plot_env$discrete$month >= 10, ]$value) /
                   sum(plot$plot_env$stats_discrete[plot$plot_env$stats_discrete$type == "median" &
                                            (plot$plot_env$stats_discrete$month <= params$month | 
                                            plot$plot_env$stats_discrete$month >= 10), ]$value) * 100)
  return(list(plot, stats_c))
}

#### --------------- D: Functions to create CDDF plots -------------------- ####

# Function for calculating CDDF
getCDDF <- function(temps, year) {

  # Function for calculating cddf of dataframe (with all dates of interest)
calcCDDF <- function(temps) {
  cddf <- 0
  temps$cddf <- NA
  for (d in 1:length(temps$value)) {
    t <- temps$value[d]
    # If temperature is NA
    if (is.na(t)) {
      t <- 0
    }
    # If yesterday's cddf is 0 and todays temp is >= 0, keep cddf at 0
    if (cddf==0 & t>=0) {
      cddf <- 0
    } else { 
      cddf <- cddf - t
      if (cddf<0){cddf <- 0}}
    # Set cddf for that day
    temps$cddf[d] <- cddf
  }
return(temps)
} 


# Keep only sept-june data
temps <- temps[format(temps$datetime, "%m") %in% c("09", "10", "11", "12", "01", "02", "03", "04", "05", "06"),]

# Find first and last year 
first_yr <- format(min(temps$datetime), "%Y")
last_yr <- format(max(temps$datetime), "%Y")

# if (last_yr <= year) {
#   last_yr <- year 
# }

cddf <- data.frame()
# Run over every year
for (y in first_yr:last_yr) {
  # Subset data
    tab <- temps[temps$datetime >= paste0(y, '-09-01') 
                 & temps$datetime < paste0(y+1, '-06-14'),]
  # Only calculate if missing less than 10 days, but only for years that are not in the 'years' list
    if (length(tab$datetime) != 0) {
      if (sum(!is.na(tab$value)) >= 276 | format(min(tab$datetime), "%Y") %in% c(year-1)) {
      cddf_y <- calcCDDF(tab)
      cddf <- rbind(cddf, cddf_y)
    }
    }
}

# Rename columns and remove temp
cddf <- cddf[,c("datetime", "cddf")]
colnames(cddf) <- c("datetime", "value")

return(cddf)
}

# Function to create CDDF plots
snowbullCDDF <- function(timeseries_id, custom_title) {
  location <- DBI::dbGetQuery(con, paste0("SELECT datetime, value FROM measurements_continuous WHERE timeseries_id = ", timeseries_id))

  location <- getCDDF(location, params$year)

  plot <- YGwater::hydrometContinuous(parameter= "CDDF", 
                                      startDay = "2023-09-01", 
                                      endDay = "2024-08-31",  
                                      years = c(params$year-1), 
                                      title = TRUE, 
                                      custom_title = custom_title, 
                                      returns = "none", 
                                      allowed_missing = 10, 
                                      plot_scale = params$scale, 
                                      save_path = NULL, 
                                      con = con, 
                                      continuous_data = location, 
                                      snowbulletin = TRUE)
  plot + ggplot2::theme(legend.position = "none") + ggplot2::labs(y="CDDF (\u00B0C days)")
}


#### --------- E: Function to create lake level snow bulletin plots ------- ####

snowbullWater <- function(location, parameter, year, custom_title, scale) {
  flood <- data$flow_level_flood
  tryCatch({
  plot <-
    YGwater::hydrometContinuous(
      location = location,
      parameter = parameter,
      startDay = paste0(year, "-10-01"),
      endDay = paste0(as.character(as.numeric(year) + 1), '-09-30'),
      years = year,
      returns = "none",
      custom_title = custom_title,
      con = con,
      plot_scale = scale * 0.9,
      snowbulletin = TRUE
    )
  #plot <- plot + ggplot2::geom_line(ggplot2::aes(y=zoo::rollmean(max,5, fill=NA)), colour = "#0097A9", size=1) +
   # ggplot2::geom_line(ggplot2::aes(y=zoo::rollmean(min,5, fill=NA)), colour = "#834333", size=1)
  
  if (exists('flood') &
      !is.null(flood) & parameter %in% c("water level", "water flow")) {
    if (parameter == "water level") {
      plot <- plot +
        ggplot2::geom_hline(
          yintercept = dplyr::filter(flood, ID == location)$Flood_level_asl,
          linetype = "dashed",
          color = "red",
          size = 1
        )# +
        # ggplot2::annotate(
        #   "text",
        #   x = as.POSIXct(paste0(year+1, "-03-25")),
        #   y = dplyr::filter(flood, ID == location)$Flood_level_asl, #+ (max(plot$data$max)-min(plot$data$min))/20,
        #   label = "Flood level",
        #   colour = "red",
        #   vjust = -0.5
        # )
    } else {
      plot <- plot +
        ggplot2::geom_hline(
          yintercept = dplyr::filter(flood, ID == location)$Flood_flow,
          linetype = "dashed",
          color = "red",
          size = 1
        ) +
        # ggplot2::annotate(
        #   "text",
        #   x = as.POSIXct(paste0(year+1, "-03-25")),
        #   y = dplyr::filter(flood, ID == location)$Flood_flow,  #+ (max(plot$data$max)-min(plot$data$min)),
        #   label = "Flood level",
        #   colour = "red",
        #   vjust = -0.5
        #   ) + 
        ggplot2::scale_y_log10()
    }
    
  } else {
    plot <- plot
  }
  
  plot <- plot + ggplot2::theme(legend.position = "none") 
  
  return(plot)
  },
  error = function(e) {
    message("Error when plotting flow data. It is possible that data is missing.")})
  
}



```

```{r SWEbasins, include=FALSE, eval=FALSE}
# Get SWE data for basins 
swe_basins <- YGwater::SWE_basin(year = params$year,
                                   month = c(3, 4, 5), # c(3)
                                   threshold = 6,
                                   csv = FALSE,
                                   summarise = FALSE)
  # Add datetime to data
  swe_basins$datetime <- paste0(swe_basins$year, "-0", swe_basins$month, "-01")
  swe_basins <<- swe_basins
# Get stats for text
  # Basin % historical median and SWE on target date
  basins_stats <- YGwater::SWE_basin(year = params$year,
                                     month = params$month, # c(3)
                                     threshold = 6,
                                     csv = FALSE,
                                     summarise = TRUE)
  basins_stats <- basins_stats[,c("basin", "swe", "swe_relative")]
  basins_stats$swe <- round(basins_stats$swe, 0)
  basins_stats <<- basins_stats

  # Snow pillow/scale % of historical median
  pillow_stats <- DBI::dbGetQuery(con, paste0("SELECT value, q50, location FROM calculated_daily 
                  INNER JOIN timeseries ON calculated_daily.timeseries_id = timeseries.timeseries_id
                  WHERE calculated_daily.timeseries_id IN (20, 145, 51, 75, 122, 85)
                  AND date = '", params$year, "-0", params$month, "-01'"))
  pillow_stats$perc <- round(pillow_stats$value / pillow_stats$q50 * 100)
  pillow_stats <<- pillow_stats

```

<br>

<br>

<br>

<br>

![](logo.png)

<br>

<br>

<br>

<br>

# Preface

The Department of Environment's Water Resources Branch issues the Yukon
Snow Survey Bulletin and Water Supply Forecast three times annually --
early March, April and May. The bulletin provides a summary of winter
meteorological and streamflow conditions for the Yukon, as well as
current snow depth and snow water equivalent observations for 57
locations. This information is used to evaluate the potential for spring
flooding caused by both breakup ice jams and large spring snowmelt
(freshet) flows. It is important to note that other processes such as
summer rain and glacier melt can significantly influence maximum annual
water levels in specific Yukon basins. March weather conditions for the
Yukon are presented in two maps, one showing temperature anomalies
(deviation from climate normals), and another showing precipitation
anomalies. Territory-wide snowpack data are presented in a third map
showing snow water equivalent (SWE) as a percent of historical median
for each station, as well as the basinaveraged estimated SWE for 11
watersheds (or river basins). Complementary meteorological and
hydrological data are presented for each basin through a series of five
graphs, depending on data availability:

-   **Figure A:** Daily Snow Water Equivalent (SWE) data starting in
    September at one specific location in the watershed, showing an
    overview of winter snowpack evolution.
-   **Figure B:** Current, basin-averaged, estimated Snow Water
    Equivalent (SWE) from snow survey data, compared with historical
    data, serving as an indicator of potential runoff volumes in the
    spring (acknowledging that snow sublimation, evapotranspiration,
    rain and glacier melt also significantly affect runoff).
-   **Figure C:** Monthly winter precipitation (rain and/or snow)
    compared with historical data, complementing the information
    presented in Figure B.
-   **Figure D:** Cumulated degree-days of freezing (CDDF, sum of
    negative daily temperatures) compared with historical data,
    functioning as an indicator of winter coldness and overall river ice
    thickness; variables that influence river ice breakup scenarios in
    the spring.
-   **Figure E:** Current, estimated daily discharge or measured water
    level, compared with historical data, representing an overview of
    the watershed hydrological conditions.

```{r legend, echo=FALSE, eval=TRUE, fig.align='center', out.width="40%"}

lines <- c("Maximum observed value", "Minimum observed value", "Median observed value", "Current year", "Flood level", "25th-75th percentile range \nof observed values", "Min - max range of \nobserved values")  # Example list of unique legend elements

# Test 1
 plot <- ggplot2::ggplot() +
  ggplot2::theme_void() + 
  ggplot2::theme(legend.position = c(0.5,0.5), 
                 legend.text=ggplot2::element_text(size=12), 
                 legend.title=ggplot2::element_text(size=12),
                 legend.spacing.x = ggplot2::unit(0.5, 'cm'),
                 legend.spacing.y = ggplot2::unit(0.6, 'cm'),
                 legend.key.width= ggplot2::unit(2, "cm"),
                 aspect.ratio = 1,
                 legend.background = ggplot2::element_blank(),
                 legend.box.background = ggplot2::element_rect(colour = "black"),
                 #legend.title.margin = ggplot2::margin(b = 10),
                 legend.margin = ggplot2::margin(t = 0.3, r=0.3, b=0.3, l=0.3, unit="cm")
                 ) +  # Adjust legend position as needed
  #ggplot2::labs(legend.title = "Figure Legend") +  # Set legend title
  ggplot2::scale_color_manual(name = "Figure Legend", values = c("#0097A9", "#834333", "#7A9A01", "black", "red", "gray80", "gray90"), labels = lines) +  # Customize legend entries for color
  ggplot2::scale_size_manual(name = "Figure Legend", values = c(1.5, 1.5, 1.5, 1.5, 1, 10, 10), labels = lines) +  # Customize legend entries for fill
  ggplot2::scale_linetype_manual(name = "Figure Legend", values = c("solid", "solid", "solid", "solid", "dashed", "solid", "solid"), labels = lines) +  # Customize legend entries for shape
  #theme_minimal() +  
   ggplot2::geom_line(ggplot2::aes(x=1, y=1, color= lines, size=lines, linetype=lines)) +
  ggplot2::guides(color = ggplot2::guide_legend(byrow = TRUE
                                                #,title.vjust=-1
                                                ))
 
 ggplot2::ggsave("test_plot.png", plot=plot, width=3.3, height=5.3)
 
 knitr::include_graphics("test_plot.png")

```

For information about the bulletin, snowpack conditions, or streamflow
projections please contact
[waterlevels\@yukon.ca](mailto:waterlevels@yukon.ca){.email}

Water Resources Branch, Department of Environment\
(867) 667-3171, toll free (in Yukon, NWT, Nunavut): 1-800-661-0408, ext.
3171\
Fax: 867-667-3195 \| Email:
[waterresources\@yukon.ca](mailto:waterresources@yukon.ca){.email}

This bulletin, as well as earlier editions, are available online at:\
Yukon.ca/snow-survey

ISSN 1705-883X

Reference to this report should be made in the following form:\
Yukon Snow Survey Bulletin and Water Supply Forecast,
`r month.name[params$month]` 1, `r params$year`

Â© `r month.name[params$month]` `r params$year`\
Water Resources Branch\
Department of Environment\
Government of Yukon\
Box 2703, Whitehorse, Yukon Y1A 2C6

# Acknowledgements

The Yukon Snow Survey Bulletin forms part of the Yukon Snow Survey
Program administered by the Water Resources Branch, Department of
Environment, Government of Yukon. The Water Resources Branch (WRB)
strives for water stewardship in the Yukon and is committed to
responsible and collaborative monitoring to inform the management and
protection of waters.

We are grateful to monitor snow and water across the territories of all
fourteen Yukon First Nations and to work in partnership with many First
Nations in different aspects of our work. Though the findings expressed
in this report are based primarily on field observations and relevant
scientific data, we acknowledge the deep and longstanding connection to,
and knowledge of snow and water held by, Yukon First Nations.

Gathering snow measurements and data from across our vast territory
requires working together with a number of partners. We'd like to
recognize the following agencies/individuals for their significant
contributions to the snow survey bulletin:

-   *Data Collection Officer, Natural Resources Conservation Service,
    United States Department of Agriculture*
-   *Meteorologist, Wildland Fire Management, Yukon Department of
    Community Services, Whitehorse*
-   *Officer in Charge, Water Survey of Canada, Whitehorse*
-   *Water Management Engineer, Yukon Energy Corporation*
-   *Research Technologists, McMaster University*

Agencies cooperating with Environment Yukon in the Snow Survey Program
are:

-   *B.C. Ministry of Environment, Water Stewardship Division*
-   *Parks Canada, Kluane National Park and Reserve*
-   *Yukon Department of Highways and Public Works*
-   *Yukon Department of Energy Mines and Resources, Compliance
    Monitoring and Inspections Branch*
-   *Yukon Department of Environment, Information Management and
    Technology Branch*
-   *Vuntut Gwitchin First Nation*

# Disclaimer and Limitation of Liability

The User understands and acknowledges that the use of the data is solely
at their own risk. The User is solely responsible for confirming the
accuracy, availability, suitability, reliability, usability,
completeness or timeliness of the data.

The User accepts the data "as is" and acknowledges that the Government
of Yukon makes no warranties or representations (express or implied)
with respect to the accuracy, availability, suitability, reliability,
usability, completeness or timeliness of the data, including, without
limitation, implied warranties for merchantability, fitness for a
particular purpose, and non-infringement.

In consideration of access to the data, the User also agrees that in no
event will the Government of Yukon be liable (in tort or contract) or
responsible whatsoever to the User or any other legal entity for the
accuracy, availability, suitability, reliability, usability,
completeness or timeliness of the data, including, without limitation,
any loss of revenue or profit, or for direct, indirect, special,
incidental, or consequential damages arising from or related to the
data.

# Yukon Territory Weather and Snowpack Conditions

**October**

**November**

**December**

**January**

**February**

**March**

**April**

**Snowpack**

# Yukon Territory Flow Conditions and Outlook

# All basins

```{r All_basins, echo=FALSE, fig.width=10}
# Box plot of SWE of all basins
hydrometDiscrete2 <- function(location=NULL,
                             parameter,
                             startDay = 1,
                             endDay = 365,
                             tzone = "MST",
                             years = NULL,
                             title = TRUE,
                             plot_type = "violin",
                             plot_scale = 1,
                             save_path = NULL,
                             dbPath = "default",
                             discrete_data = NULL)
{
  # # Commented code below is for testing...
  # # location = "08AA-SC01"
  # # parameter = "SWE"
  # # startDay = 1
  # # endDay = 365
  # # tzone = "MST"
  # # years = c(2022)
  # # title = TRUE
  # # plot_scale = 1
  # # plot_type = "boxplot"
  # # save_path = NULL
  # # dbPath ="default"
  # # discrete_data = NULL
  # 
  # #TODO Should give a decent error message if the user requests something that doesn't exist. Station not existing, timeseries not existing, years not available (and where they are), etc.
  # 
  # if (startDay != 1){
  #   startDay <- 1
  #   message("Parameter startDay is not currently in use and has been reset to the default of 1.")
  # }
  # if (endDay != 365){
  #   endDay <- 365
  #   message("Parameter endDay is not currently in use and has been reset to the default of 365.")
  # }
  # 
  # # Checks on input parameters  and other start-up bits------------------
  # if (parameter != "SWE"){
  #   parameter <- tolower(parameter)
  # }
  # 
  # plot_type <- tolower(plot_type)
  # if (!(plot_type %in% c("violin", "boxplot"))){
  #   stop("Parameter 'plot_type' must be one of 'violin' or 'boxplot'")
  # }
  # 
  # if (is.null(years)){
  #   years <- as.numeric(substr(Sys.Date(), 1, 4))
  # } else {
  #   years <- as.numeric(years)
  #   years <- sort(years, decreasing = TRUE)
  #   if (length(years) > 10){
  #     years <- years[1:10]
  #     print("The parameter 'years' can only have up to 10 years. It's been truncated to the first 10 years in the vector.")
  #   }
  # }
  # # Select save path
  # if (!is.null(save_path)){
  #   if (save_path %in% c("Choose", "choose")) {
  #     print("Select the folder where you want this graph saved.")
  #     save_path <- as.character(utils::choose.dir(caption="Select Save Folder"))
  #   }
  # }
  # 
  # 
  # if (is.null(discrete_data)) {
  #   #Connect
  #   con <- hydrometConnect(path = dbPath, silent = TRUE)
  #   on.exit(DBI::dbDisconnect(con))
  # 
  #   # Dealing with start/end dates ----------------------
  #   # Sort out startDay and endDay into actual dates if needed
  #   last_year <- max(years)
  #   leap_list <- (seq(1800, 2100, by = 4))  # Create list of all leap years
  #   tryCatch({
  #     startDay <- as.character(startDay)
  #     startDay <- as.POSIXct(startDay, tz = tzone)
  #     lubridate::year(startDay) <- last_year
  #   }, error = function(e) {
  #     if (last_year %in% leap_list){
  #       if (startDay > 59){
  #         startDay <<- startDay + 1
  #       }
  #     }
  #     startDay <<- as.POSIXct(as.numeric(startDay)*60*60*24, origin = paste0(last_year-1, "-12-31"), tz = "UTC")
  #     startDay <<- lubridate::force_tz(startDay, tzone)
  #   })
  #   tryCatch({
  #     endDay <- as.character(endDay)
  #     endDay <- as.POSIXct(endDay, tz = tzone)
  #     lubridate::year(endDay) <- last_year
  #   }, error = function(e) {
  #     tempStartDay <- lubridate::yday(startDay) #using yday because start is now in proper Date format and needs to be back-converted to yday
  #     if (last_year %in% leap_list){
  #       if (endDay > 59){
  #         endDay <<- endDay + 1
  #       }
  #     }
  #     endDay <<- as.POSIXct(as.numeric(endDay)*60*60*24, origin = paste0(last_year-1, "-12-31 23:59:59"), tz = "UTC")
  #     endDay <<- lubridate::force_tz(endDay, tzone)
  #   })
  #   if (startDay > endDay){ #if the user is wanting a range overlapping the new year
  #     lubridate::year(endDay) <- lubridate::year(endDay)+1
  #     overlaps <- TRUE
  #   } else {
  #     overlaps <- FALSE
  #   }
  # 
  #   day_seq <- seq.POSIXt(startDay, endDay, by = "day")
  # 
  #   #Check for existence of timeseries, then for presence of data within the time range requested.
  #   exists <- DBI::dbGetQuery(con, paste0("SELECT * FROM timeseries WHERE location = '", location, "' AND parameter = '", parameter, "' AND type = 'discrete'"))
  #   if (nrow(exists) == 0){
  #     stop("There is no entry for the location and parameter combination that you specified of discrete data type. If you are trying to graph continuous data use hydrometContinuous.")
  #   } else if (nrow(exists) > 1){
  #     stop("There is more than one entry in the database for the location and parameter that you specified! Please alert the database manager ASAP.")
  #   }
  # 
  # 
  # 
  #   #Find the ts units
  #   units <- DBI::dbGetQuery(con, paste0("SELECT units FROM timeseries WHERE parameter = '", parameter, "' AND location = '", location, "'"))
  # 
  #   # Get the data ---------------------
  #   all_discrete <- DBI::dbGetQuery(con, paste0("SELECT * FROM discrete WHERE location = '", location, "' AND parameter = '", parameter, "' AND sample_date < '", paste0(max(years), substr(endDay, 5, 10)), "'"))
  #   if (nrow(all_discrete) == 0){
  #     stop(paste0("There doesn't appear to be any data for the year and days you specified: this timeseries starts ",  exists$start_datetime_UTC))
  #   }
  #   all_discrete$target_date <- as.Date(all_discrete$target_date)
  #   all_discrete$sample_date <- as.Date(all_discrete$sample_date)
  #   all_discrete$year <- lubridate::year(all_discrete$target_date)
  #   all_discrete$month <- lubridate::month(all_discrete$target_date)
  #   all_discrete$day <- lubridate::day(all_discrete$target_date)
  #   #Separate, modify, and re-bind feb29 days, if any
  #   feb29 <- all_discrete[all_discrete$month == 2 & all_discrete$day == 29, ]
  #   if (nrow(feb29) > 0){
  #     all_discrete <- all_discrete[!(all_discrete$month == 2 & all_discrete$day == 29), ]
  #     feb29$target_date <- feb29$target_date + 1
  #     feb29$month <- 3
  #     feb29$day <- 1
  #     all_discrete <- rbind(all_discrete, feb29)
  #   }
  # 
  #   #Make a fake date
  #   all_discrete$fake_date <- as.Date(gsub("[0-9]{4}", last_year, all_discrete$target_date))
  #   discrete <- data.frame()
  #   for (i in years){
  #     start <- as.Date(paste0(i, substr(startDay, 5, 10)))
  #     end <- as.Date(paste0(i, substr(endDay, 5, 10)))
  #     if (overlaps){
  #       lubridate::year(end) <- lubridate::year(end) +1
  #     }
  #     new_discrete <- all_discrete[all_discrete$target_date >= start & all_discrete$target_date <= end , ]
  #     discrete <- rbind(discrete, new_discrete)
  #   }
  #   if (nrow(discrete) == 0){
  #     stop("There is no data to graph after filtering for your specified year(s) and day range. Try again with different days.")
  #   }
  # 
  # }
  # 
  # if (!is.null(discrete_data)) {
  #   ## Create all_discrete
  #   all_discrete <- discrete_data
  #   # add fake_date
  #   all_discrete$fake_date <- as.Date(paste0(max(years), "-0", all_discrete$month, "-01" ))
  #   ## Create discrete
  #   discrete <- all_discrete %>% dplyr::filter(year %in% years)
  #   ## Give units
  #   units <- unique(discrete$units)
  # 
  # }
  # 
  # #Make the plot --------------------
  #  colours = c("blue", "black", "darkorchid3", "cyan2", "firebrick3", "aquamarine4", "gold1", "chartreuse1", "darkorange", "lightsalmon4")
  # legend_length <- length(years)
  # plot <- ggplot2::ggplot(all_discrete, ggplot2::aes(x = location, y = value, group = location)) +
  #   ggplot2::labs(x = "", y = if (parameter == "SWE") paste0("SWE (", units, ")") else paste0(stringr::str_to_title(parameter), " (", units, ")")) +
  #   ggplot2::theme_classic() +
  #   ggplot2::theme(legend.position = "right", legend.justification = c(0, 0.95), legend.text = ggplot2::element_text(size = 8*plot_scale), legend.title = ggplot2::element_text(size = 10*plot_scale), axis.title.y = ggplot2::element_text(size = 12*plot_scale), axis.text.x = ggplot2::element_text(size = 9*plot_scale), axis.text.y = ggplot2::element_text(size = 9*plot_scale))
  # if (plot_type == "violin") {
  #   plot <- plot +
  #     ggplot2::geom_violin(draw_quantiles = c(0.5), adjust = 0.7, width = 12, alpha = 0.8, fill = "aliceblue", scale = "width") #Using a scale other than "width" may result in issues for locations where there are many "0" values.
  # } else if (plot_type == "boxplot"){
  #   plot <- plot +
  #     ggplot2::geom_boxplot(outlier.shape = 8 , outlier.size = 1.7*plot_scale, color = "black", fill = "aliceblue", varwidth = TRUE)
  # }
  # plot <- plot +
  #   ggplot2::geom_point(data = discrete, mapping = ggplot2::aes(x = location, y = value, colour = as.factor(year), fill = as.factor(year)), size = plot_scale*3.5, shape = 21) +
  #   ggplot2::scale_colour_manual(name = "Year", labels = unique(discrete$year), values = colours[1:legend_length], aesthetics = c("colour", "fill"), na.translate = FALSE, breaks=unique(stats::na.omit(discrete$year))[1:legend_length])
  # 
  # # Wrap things up and return() -----------------------
  # if (title == TRUE){
  #   if (is.null(discrete_data)){
  #     stn_name <- DBI::dbGetQuery(con, paste0("SELECT name FROM locations where location = '", location, "'"))
  #     titl <- paste0("Location ", location, ": ", stn_name)
  #   } else {
  #     if (!is.null(location)) {
  #       titl <- paste0("Location: ", location)}
  #     else {
  #       titl <- paste0("Location: ", unique(all_discrete$location))
  #       }
  # 
  #   }
  # 
  #   plot <- plot +
  #     ggplot2::labs(title=titl) +
  #     ggplot2::theme(plot.title=ggplot2::element_text(hjust=0.05, size=14*plot_scale))
  # }
  # 
  # #Save it if requested
  # if (!is.null(save_path)){
  #   ggplot2::ggsave(filename=paste0(save_path,"/", location, "_", parameter, "_", Sys.Date(), "_", lubridate::hour(as.POSIXct(format(Sys.time()), tz=tzone)), lubridate::minute(as.POSIXct(format(Sys.time()), tz=tzone)), ".png"), plot=plot, height=8, width=12, units="in", device="png", dpi=500)
  # }
  # 
  # return(plot)
}
all_basins <- swe_basins[swe_basins$month == 5,]
plot <- hydrometDiscrete2(location = "all basins", parameter = "SWE", startDay = 1, tzone = "MST", years = params$year, title = FALSE, plot_type = "boxplot", plot_scale = 1, save_path = NULL, discrete_data = all_basins)

```

# Upper Yukon River Basin (Southern Lakes/Whitehorse)

The Upper Yukon River Basin snowpack is \-\-\-\-- average. At Tagish
Meteorological Station, Snow Water Equivalent (SWE) is estimated to be
**`r pillow_stats[pillow_stats$location=='09AA-M1',]$perc`%** of the
historical median (Figure A1), while at Wolf Creek Subalpine
Meteorological Station, SWE is estimated to be
**`r pillow_stats[pillow_stats$location=='29AB-M3',]$perc`%** of the
historical median (Figure A2). Established in 2023, the Log Cabin
Meteorological Station registered Snow Water Equivalent (SWE) at \-\--%
of the historical median when compared with the manual snow survey
record for that site (Figure A3). The Upper Yukon basin-averaged SWE is
estimated to be
**`r basins_stats[basins_stats$basin=='Upper_Yukon',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Upper_Yukon',]$swe`** **mm** as
of `r month.name[params$month]` 1 (Figure B).

```{r Upper Yukon, echo=FALSE}
# Run or don't run following chunks
if ("Upper Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Plot C 
# Create plot C
plot_c <- snowBullPrecip(663, params$year, params$scale, "C: Whitehorse Monthly Precipitation")

```

```{r UpperYukonRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
#r UpperYukonRiver_Snow, echo=FALSE, eval=include, out.width='.49\\linewidth', fig.width=4, fig.height=3,fig.show='hold',fig.align='center'
par(mfrow = c(1, 2))
## A1 Tagish
# Set station ID
station_id <- "09AA-M1"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A1: Tagish Snow Water Equivalent", year = params$year)

## A2 Wolf Creek
# Set station ID
station_id <- "29AB-M3"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A2: Wolf Creek Subalpine Snow Water Equivalent", year = params$year)



```

```{r UpperYukon_basin, echo=FALSE, eval=include, out.width="50%", fig.align='center', fig.height=fig.height_half}
par(mfrow = c(1, 2))
## A3: Log Cabin
# Get this years snow pillow
snow_p <- DBI::dbGetQuery(con, paste0("SELECT date, value FROM calculated_daily ",
                            "WHERE timeseries_id = 649 ",
                            "AND date >= '", params$year-1, "-09-01' ", #params$year
                            "AND date <= '", params$year, "-07-01' ")) #params$year
# Get historical snow survey data
snow_s <- DBI::dbGetQuery(con, paste0("SELECT target_datetime, value FROM measurements_discrete ",
                            "WHERE timeseries_id = 217 "))
  snow_s$fake_date <- as.Date(paste0(params$year, "-", format(snow_s$target_datetime, "%m-%d"))) #params$year
  # Only keep those for March, April, May
  snow_s <- snow_s[format(snow_s$fake_date, "%m-%d") %in% c("03-01", "04-01", "05-01"),]
  # Calculate stats
  snow_s <- snow_s %>%
      dplyr::group_by(.data$fake_date) %>%
      dplyr::summarise(value = min(.data$value), type = "min") %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = max(.data$value), type = "max")) %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = stats::median(.data$value), type = "median"))
  
  plot_scale <- params$scale

ggplot2::ggplot() +
  ggplot2::theme_classic() +
  ggplot2::geom_line(data=snow_p, ggplot2::aes(y=value, x=date), linewidth = plot_scale *1) +
  ggplot2::geom_point(dat=snow_s, ggplot2::aes(y=value, x=fake_date, colour=type), size=plot_scale*2) +
  ggplot2::scale_color_manual(name = "", labels = c("Maximum", "Median", "Minimum"), values=c("#0097A9", "#7A9A01", "#834333")) +
  ggplot2::theme(legend.position = "none") +
  ggplot2::theme(axis.title.y = ggplot2::element_text(size = 11*plot_scale), axis.text.x = ggplot2::element_text(size = 9*plot_scale), axis.text.y = ggplot2::element_text(size = 9*plot_scale), plot.title=ggplot2::element_text(hjust=0.05, size=12*plot_scale, face="bold")) +
  ggplot2::labs(x = "", y = "SWE (mm)", title = "A3: Log Cabin (B.C) Snow Water Equivalent")

# B
# Plotting 
snowbullSWE(loc= "Upper Yukon", basin = "Upper_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Upper Yukon Basin Monthly Snow Course")
```

Whitehorse precipitation has been ----- median since October... (Figure C). 
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1. 
Cumulative degreedays of freezing (CDDF) are ---% below/above average, with -----$^\circ$C-Days on
`r month.name[params$month]` 1 (Figure D), which suggests that the
thickness of the ice cover on rivers and lakes of the region is likely
----- than normal.

```{r UpperYukon_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", warnings=FALSE, fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]

# D
snowbullCDDF(timeseries_id = 484, custom_title = "D: Cumulative Degree-Days of Freezing in Whitehorse")

```

The measured water surface elevation (relative to sea level) in Marsh
Lake is currently \-\-\-\-- average (Figure E). The current snow and
groundwater conditions suggest that water levels will be \-\-\-\--
average this summer. However, weather conditions over the spring and
summer will determine the peak water level in Marsh Lake, which
typically occurs in late summer in response to peak glacial runoff and
large precipitation events. Lake Laberge level is currently \-\-\-\--
the historic maximum for this time of year (Figure E2). Lake Laberge
follows a similar summer pattern to the upper Southern Lakes and is
expected to experience \-\-\-\-- average water levels this summer.

```{r MarshLake, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E1
# Set station ID
station_id <- "09AB004"
# Plotting
snowbullWater(location = station_id,
              parameter = "water level",
              year = params$year-1, #2023, #
              custom_title = "E1: Marsh Lake Water Surface Elevation",
              scale = params$scale)
```

```{r LakeLaberge, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E2
# Set station ID
station_id <- "09AB010"
# Plotting
snowbullWater(location = station_id,
              parameter = "water level",
              year = params$year-1,
              custom_title = "E2: Lake Laberge Water Surface Elevation",
              scale = params$scale)
```

# Teslin River Basin

The Teslin River Basin snowpack is \-\-\-\-- average. The basin-averaged
SWE is estimated at
**`r basins_stats[basins_stats$basin=='Teslin_Big_Salmon',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Teslin_Big_Salmon',]$swe`**
**mm** as of `r month.name[params$month]` 1 (Figure B).

```{r Teslin, echo=FALSE}
if ("Teslin" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Plot C
plot_c <- snowBullPrecip(665, params$year, params$scale, "C: Teslin Monthly Precipitation")
```

```{r TeslinBigSalmon_basin, echo=FALSE, eval=include, fig.align='center', out.width="50%", fig.height=fig.height_half}
# B
# Plotting
snowbullSWE(loc= "Teslin - Big Salmon", basin = "Teslin_Big_Salmon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Teslin - Big Salmon Basin Monthly Snow Course")
```

Teslin precipitation has been \-\-\-\-- median since October... (Figure C). 
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1.

```{r Teslin_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 532, custom_title = "D: Cumulative Degree-Days of Freezing in Teslin")

```

The measured water surface elevation (relative to sea level) in Teslin
Lake is currently \-\-\-\-- average (Figure E). The \-\-\-\-- snowpack
and \-\-\-\-- water level suggest that summer water levels will be
\-\-\-\--.

```{r TeslinLake, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09AE002"
# Plotting
snowbullWater(location = station_id,
              parameter = "water level",
              year = params$year-1,
              custom_title = "E: Teslin Lake Water Surface Elevation",
              scale = params$scale)
```

# Central Yukon River Basin (Carmacks Area)

```{r Central Yukon, echo=FALSE}
if ("Central Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Create plot C
plot_c <- snowBullPrecip(666, params$year, params$scale, "C: Carmacks Monthly Precipitation")
```

The Central Yukon River Basin snowpack is \-\-\-\-- average. The
basin-averaged SWE is estimated to be
**`r basins_stats[basins_stats$basin=='Central_Yukon',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Central_Yukon',]$swe`** **mm** as
of `r month.name[params$month]` 1 (Figure B).

```{r CentralYukon_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
# B
# Plotting
snowbullSWE(loc= "Central Yukon", basin = "Central_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Central Yukon Basin Monthly Snow Course")
```

Carmacks precipitation has been \-\-\-\-- median since October... (Figure C). 
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1. 
Cumulated degree-days of freezing (CDDF) are \-\-- % ----- average, with \-\-\-\--$^\circ$C-Days on `r month.name[params$month]` 1 (Figure D).

```{r Carmacks_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 540, custom_title = "D: Cumulative Degree-Days of Freezing in Carmacks")

```

The estimated Nordenskiold River discharge is currently \-\-\-\--
average (Figure E). The \-\-\-\-- average snowpack combined with
\-\-\-\-- winter flows in the watershed suggests spring freshet flow
volumes will be \-\-\-\-- average with a potential for.... A combination
of local conditions such as ice thickness, freeze-up levels, and current
flow volumes suggest a \-\-\-\-- average ice jam risk. Weather patterns
leading to breakup and the spring freshet will play a critical role in
determining potential ice jam severity and peak water levels.

```{r Nordenskiold, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09AH004"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Nordenskiold River Discharge below Rowlinson Creek",
              scale = params$scale)
```

# Pelly River Basin

```{r Pelly, echo=FALSE}
if ("Pelly" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
```

The Pelly River Basin snowpack is \-\-\-\-- average. At Twin Creeks
Meteorological Station, Snow Water Equivalent (SWE) is estimated to be
**`r pillow_stats[pillow_stats$location=='09BA-M7',]$perc`%** of the
historical median (Figure A). The Pelly River basin-averaged SWE is
estimated to be
**`r basins_stats[basins_stats$basin=='Pelly',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Pelly',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r Pelly_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
## A Twin Creeks
# Set station ID
station_id <- "09BA-M7"
# Plot SWE
plot <- snowbullpillow(location = station_id, custom_title = "A: Twin Creeks Snow Water Equivalent", year = params$year)
plot
# B
# Plotting 
snowbullSWE(loc= "Pelly", basin = "Pelly",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Pelly Basin Monthly Snow Course")

```

Precipitation at Faro has not been recorded, but snowpack observations
indicate values are \-\-\-\-- the climate normals. Cumulated degree-days
of freezing (CDDF) at Faro are \-\--% \-\-\-\-- average at
2249$^\circ$C-Days on `r month.name[params$month]` 1 (Figure D), which
suggests that the thickness of the ice cover on rivers and lakes of the
region is likely \-\-\-\-- than normal

```{r Faro_CDDF, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
# D
snowbullCDDF(timeseries_id = 500, custom_title = "D: Cumulative Degree-Days of Freezing in Faro")

```

The estimated Pelly River discharge at Pelly Crossing is currently
\-\-\-\-- average (Figure E). The \-\-\-\-- average snowpack combined
with \-\-\-\-- winter flows in the watershed suggests spring freshet
flow volumes will be \-\-\-\-- average with a potential for \-\-\-\--
spring freshet flows. A combination of local conditions such as ice
thickness, freeze-up levels, and current flow volumes suggest a
\-\-\-\-- average ice jam risk. Weather patterns leading to breakup and
the spring freshet will play a critical role in determining potential
ice jam severity and peak water levels.

```{r PellyRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09BC001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Pelly River Discharge at Pelly Crossing",
              scale = params$scale)
```

# Stewart River Basin

```{r Stewart, echo=FALSE}
if ("Stewart" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Create plot c
plot_c <- snowBullPrecip(668, params$year, params$scale, "C: Mayo Monthly Precipitation")
```

The Stewart River Basin snowpack is \-\-\-\-- average. At Withers Lake
Meteorological Station, Snow Water Equivalent (SWE) is estimated to be
**`r pillow_stats[pillow_stats$location=='09DB-M1',]$perc`%** of the
historical median (Figure A). The The Stewart River basin-averaged SWE
is estimated to be
**`r basins_stats[basins_stats$basin=='Stewart',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Stewart',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r StewartRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
## A Withers Lake
# Set station ID
station_id <- "09DB-M1"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A: Withers Lake Snow Water Equivalent", year = params$year)
# B
# Plotting 
snowbullSWE(loc= "Stewart", basin = "Stewart",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Stewart Basin Monthly Snow Course")

```

Mayo precipitation has been \-\-\-\-- median since October...(Figure c).
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1. 
Cumulated degree-days of freezing (CDDF) are \-\--% \-\-\-\-- average, with 2533$^\circ$C-Days on
`r month.name[params$month]` 1 (Figure D), which suggests that the
thickness of the ice cover on rivers and lakes of the region is likely
\-\-\-\-- than normal.

```{r Mayo_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 548, custom_title = "D: Cumulative Degree-Days of Freezing in Mayo")

```

The estimated Stewart River discharge at the outlet is currently
\-\-\-\-- average (Figure E). The \-\-\-\-- average snowpack combined
with \-\-\-\-- winter flows in the watershed suggests spring freshet
flow volumes will be \-\-\-\-- average. A combination of local
conditions such as ice thickness, freeze-up levels, and current flow
volumes suggest a \-\-\-\-- average ice jam risk. Weather patterns
leading to breakup and the spring freshet will play a critical role in
determining potential ice jam severity and peak water levels.

```{r StewartRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09DD003"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Stewart River Discharge at Outlet",
              scale = params$scale)
```

# White River Basin

```{r White, echo=FALSE}
if ("White" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
```

The White River Basin snowpack is \-\-\-\-- average. The basin-averaged
SWE is estimated to be
**`r basins_stats[basins_stats$basin=='White',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='White',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r White_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%"}
# B
# Plotting 
snowbullSWE(loc= "White", basin = "White",
            year = params$year, swe_basins = swe_basins, custom_title = "B: White Basin Monthly Snow Course")
```

The estimated White River discharge at the Alaska Highway is currently
\-\-\-\-- average (Figure E). In this watershed, high flows are
dominated by mountain snowmelt and glacial melt that are largely
influenced by summer temperatures and precipitation. The \-\-\-\--
average snowpack combined with \-\-\-\-- average winter flows suggests
spring freshet flow volumes will be \-\-\-\-- average with a potential
for \-\-\-\-- spring freshet water levels. Warm and/or wet weather
anomalies during the next four months will \-\-\-\-- generate high peak
flows, including in rivers and streams crossing the Alaska Highway in
the Kluane region

```{r WhiteRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09CB001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: White River Discharge at Alaska Highway",
              scale = params$scale)
```

# Lower Yukon River Basin (Dawson Area)

```{r Lower Yukon, echo=FALSE}
if ("Lower Yukon" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Create plot C
plot_c <- snowBullPrecip(664, params$year, params$scale, "C: Dawson Monthly Precipitation")

```

The Lower Yukon River Basin snowpack is \-\-\-\-- average. Established
in 2022, the King Solomon Dome Meteorological Station registered Snow
Water Equivalent (SWE) at \-\--% of the historical median when compared
with the manual snow survey record for that site (Figure A). The Lower
Yukon basin-averaged SWE is estimated to be
**`r basins_stats[basins_stats$basin=='Lower_Yukon',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Lower_Yukon',]$swe`** **mm** as
of `r month.name[params$month]` 1 (Figure B).

```{r LowerYukonRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}

par(mfrow = c(1, 2))

## A King Solomon Dome
# Get this years snow pillow
snow_p <- DBI::dbGetQuery(con, paste0("SELECT date, value FROM calculated_daily ",
                            "WHERE timeseries_id = 85 ",
                            "AND date >= '", params$year-1, "-09-01' ", #params$year
                            "AND date <= '", params$year, "-07-01' ")) #params$year
# Get historical snow survey data
snow_s <- DBI::dbGetQuery(con, paste0("SELECT target_datetime, value FROM measurements_discrete ",
                            "WHERE timeseries_id = 317 "))
  snow_s$fake_date <- as.Date(paste0(params$year, "-", format(snow_s$target_datetime, "%m-%d"))) #params$year
  # Only keep those for March, April, May
  snow_s <- snow_s[format(snow_s$fake_date, "%m-%d") %in% c("03-01", "04-01", "05-01"),]
  # Calculate stats
  snow_s <- snow_s %>%
      dplyr::group_by(.data$fake_date) %>%
      dplyr::summarise(value = min(.data$value), type = "min") %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = max(.data$value), type = "max")) %>%
      dplyr::bind_rows(snow_s %>%
                  dplyr::group_by(.data$fake_date) %>%
                  dplyr::summarise(value = stats::median(.data$value), type = "median"))
  
  plot_scale <- params$scale

ggplot2::ggplot() +
  ggplot2::theme_classic() +
  ggplot2::geom_line(data=snow_p, ggplot2::aes(y=value, x=date), linewidth = plot_scale *1) +
  ggplot2::geom_point(dat=snow_s, ggplot2::aes(y=value, x=fake_date, colour=type), size=plot_scale*2) +
  ggplot2::scale_color_manual(name = "", labels = c("Maximum", "Median", "Minimum"), values=c("#0097A9", "#7A9A01", "#834333")) +
  ggplot2::theme(legend.position = "none") +
  ggplot2::theme(axis.title.y = ggplot2::element_text(size = 11*plot_scale), axis.text.x = ggplot2::element_text(size = 9*plot_scale), axis.text.y = ggplot2::element_text(size = 9*plot_scale), plot.title=ggplot2::element_text(hjust=0.05, size=12*plot_scale, face="bold")) +
  ggplot2::labs(x = "", y = "SWE (mm)", title = "A: King Solomon Dome Snow Water Equivalent")
  

# B
# Plotting 
snowbullSWE(loc= "Lower Yukon", basin = "Lower_Yukon",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Lower Yukon Basin Monthly Snow Course")

```

Precipitation at Dawson Airport has been \-\-\-\- median since October... (Figure C). 
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1. 
Cumulated degree-days of freezing (CDDF) are \-\--% \-\-\-\-- average, with
\-\-\-\--$^\circ$C-Days on `r month.name[params$month]` 1 (Figure D),
which suggests that the thickness of the ice cover on rivers and lakes
of the region is likely \-\-\-\-- than normal.

```{r Dawson_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 492, custom_title = "D: Cumulative Degree-Days of Freezing in Dawson")

```

The estimated Yukon River discharge at the White River is \-\-\-\--
(Figure E). The \-\-\-\-- average snowpack combined with \-\-\-\--
average winter flows suggests spring freshet flow volumes will be
\-\-\-\-- average with a \-\-\-\-- potential for \-\-\-\-- spring
freshet water levels. Weather conditions in \-\-\-\-- will determine the
most probable spring scenario. A combination of local conditions such as
ice thickness, freeze-up levels, and current flow volumes suggest an
\-\-\-\-- ice jam risk. Weather patterns leading to breakup and the
spring freshet will play a critical role in determining potential ice
jam severity and peak water levels. These statements also apply to the
Klondike River.

```{r YukonRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09CD001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Yukon River Discharge at White River",
              scale = params$scale)
```

# Porcupine River Basin

```{r Porcupine, echo=FALSE}
if ("Porcupine" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Create plot C and associated stat
plot_c <- snowBullPrecip(671, params$year, params$scale, "C: Old Crow Monthly Precipitation")

```

The Porcupine River Basin snowpack is \-\-\-\-- average. The
basin-averaged SWE is estimated to be
**`r basins_stats[basins_stats$basin=='Porcupine',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Porcupine',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r Porcupine_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
# B
# Plotting 
snowbullSWE(loc= "Porcupine", basin = "Porcupine",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Porcupine Basin Monthly Snow Course")
```

Precipitation at Old Crow Airport has been \-\-\-\-- median since October... (Figure C). 
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1. 
Cumulated degree-days of freezing (CDDF) are \-\--% \-\-\-\-- average, with
\-\-\-\-- $^\circ$C-Days on `r month.name[params$month]` 1 (Figure D),
which suggests a \-\-\-\-- average ice cover thickness on lakes and
rivers in the region.

```{r OldCrow_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 556, custom_title = "D: Cumulative Degree-Days of Freezing in Old Crow")

```

The estimated Porcupine River discharge is \-\-\-\-- average (Figure E).
The \-\-\-\-- average snowpack in the watershed suggests spring freshet
flow volumes will be \-\-\-\-- average with a potential for \-\-\-\--
spring freshet water levels. Weather patterns leading to breakup and the
spring freshet will play a critical role in determining potential ice
jam severity and peak water levels

```{r PorcupineRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "09FD002"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Porcupine River Discharge at Border",
              scale = params$scale)
```

# Peel River Basin

```{r Peel, echo=FALSE}
if ("Peel" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
```

The Peel River Basin snowpack is \-\-\-\-- average. The basin-averaged
SWE is estimated to be
**`r basins_stats[basins_stats$basin=='Peel',]$swe_relative * 100`%** of
the historical median, with
**`r basins_stats[basins_stats$basin=='Peel',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r Peel_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
# B
# Plotting 
snowbullSWE(loc= "Peel", basin = "Peel",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Peel Basin Monthly Snow Course")
```

The estimated Peel River discharge is \-\-\-\-- average (Figure E). The
\-\-\-\-- average snowpack suggests spring freshet flow volumes will be
\-\-\-\-- average with a potential for \-\-\-\-- spring freshet water
levels, including rivers and streams crossing the Dempster Highway.

```{r PeelRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "10MA001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Peel River Discharge",
              scale = params$scale)
```

# Liard River Basin

```{r Liard, echo=FALSE}
if ("Liard" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}

# Create plpot C and associated stat
plot_c <- snowBullPrecip(667, params$year, params$scale, "C: Watson Lake Monthly Precipitation")

```

The Liard River Basin snowpack is \-\-\-\-- average. At Hyland
Meteorological Station, Snow Water Equivalent (SWE) is estimated to be
**`r pillow_stats[pillow_stats$location=='10AD-M2',]$perc`%** of the
historical median (Figure A). The Liard River basin-averaged SWE is
estimated to be
**`r basins_stats[basins_stats$basin=='Liard',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Liard',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r LiardRiver_Snow, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}

par(mfrow = c(1, 2))

## A Hyland River
# Set station ID
station_id <- "10AD-M2"
# Plot SWE
snowbullpillow(location = station_id, custom_title = "A: Hyland River Snow Water Equivalent", year = params$year)

# B
# Plotting 
snowbullSWE(loc= "Liard", basin = "Liard",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Liard Basin Monthly Snow Course")

```

Precipitation at Watson Lake Airport has been \-\-\-\-- median since October... (Figure C).
Cumulative winter precipitation was **`r plot_c[[2]]`%** of historical median on `r month.name[params$month]` 1.

```{r WatsonLake_weather, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
par(mfrow = c(1, 2))
# C
plot_c[[1]]
# D
snowbullCDDF(timeseries_id = 508, custom_title = "D: Cumulative Degree-Days of Freezing Watson Lake")

```

The estimated Liard River discharge at Upper Liard is \-\-\-\-- average
(Figure E). The \-\-\-\-- average snowpack in the watershed combined
with \-\-\-\-- average winter flows suggests spring freshet flows and
levels will be \-\-\-\-- average. Weather patterns leading to spring
freshet have the potential to generate \-\-\-\-- average water levels on
small to medium creeks and rivers including those cross the Alaska and
Robert Campbell highways.

```{r LiardRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "10AA001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Liard River Discharge at Upper Liard",
              scale = params$scale)
```

# Alsek River Basin

```{r Alsek, echo=FALSE}
if ("Alsek" %in% params$basins) {
  include <- TRUE
} else {
  include <- FALSE
}
```

The Alsek River Basin snowpack is \-\-\-\-- average. The basin-averaged
SWE is estimated to be
**`r basins_stats[basins_stats$basin=='Alsek',]$swe_relative * 100`%**
of the historical median, with
**`r basins_stats[basins_stats$basin=='Alsek',]$swe`** **mm** as of
`r month.name[params$month]` 1 (Figure B).

```{r Alsek_basin, echo=FALSE, eval=include, fig.show='hold', fig.align='center', out.width="50%", fig.height=fig.height_half}
# B
# Plotting 
snowbullSWE(loc= "Alsek", basin = "Alsek",
            year = params$year, swe_basins = swe_basins, custom_title = "B: Alsek Basin Monthly Snow Course")
```

The estimated Alsek River discharge is currently \-\-\-\-- average
(Figure E). High flows in this watershed are dominated by mountain
snowmelt and glacial melt that are largely influenced by summer
temperatures and precipitation. The snowpack in the St. Elias Range is
likely to generate \-\-\-\-- average freshet volumes. Weather conditions
over the spring and summer will determine peak flows.

```{r AlsekRiver, echo=FALSE, eval=include, fig.align='center', fig.width=9, fig.height=fig.height_full}
# E
# Set station ID
station_id <- "08AB001"
# Plotting
snowbullWater(location = station_id,
              parameter = "water flow",
              year = params$year-1,
              custom_title = "E: Alsek River Discharge above Bates",
              scale = params$scale)
```

# Drainage Basin and Snow Course

```{r table, fig.width=10, results='asis', echo=FALSE}
year <- params$year
month <- params$month
tabl <- SWE_station(year=year, month=month, return_missing = TRUE, active = TRUE, source="hydromet")

tabl <- tabl[, c("location_name", "location_id", "sample_date", "depth", "swe", "swe_prevyear", "swe_med", "years", "sub_basin")]

colnames(tabl) <- c("Name", "Number", "Date of Survey", "Snow depth (cm)", "Water content (SWE) (mm)", "Last year SWE (mm)", "Median historical SWE (mm)", "Years of record", "sub_basin")

# Order rows
target <- c("Upper_Yukon", "Teslin_Big_Salmon", "Central_Yukon", "Pelly", "Stewart", "White", "Lower_Yukon", "Porcupine", "Peel", "Liard", "Alsek", "Alaska")
tabl <- tabl %>% dplyr::arrange(factor(sub_basin, levels = target))

## Change basin names
# Add River Basin to names
tabl$sub_basin <- paste0(tabl$sub_basin, " River Basin")
# Replace all _ with space
tabl$sub_basin <- gsub("_", " ", tabl$sub_basin)
tabl$sub_basin <- gsub("Alaska River Basin", "Alaska Snow Courses", tabl$sub_basin)
# Remove 'Snow Course' from name
tabl$Name <- sub(" Snow Course", "", tabl$Name)
# Single table using flextable 

flextable::as_grouped_data(tabl, groups = "sub_basin") %>% 
  flextable::as_flextable(hide_grouplabel = TRUE) %>% 
  #flextable::set_header_labels(what = "") %>% 
  flextable::bold(bold = TRUE, part="header") %>% 
  #flextable::align(i = ~ !is.na(sub_basin), align = "left") %>% 
  flextable::align(part="header", align="center") %>%
  flextable::align(align="center", j=c(2:8)) %>%
  flextable::bold(i = ~ !is.na(sub_basin)) %>%
  flextable::bg(bg="#0097A9", part="header") %>%
  #flextable::bg(bg="#77A3A9", part="header") %>%
  flextable::color(color="white", part="header") %>%
  flextable::hline(part="all") %>%
  flextable::vline(part="body") %>% 
  flextable::border_outer() %>% 
  flextable::autofit() %>%
  flextable::width(j="Number", width=1.2) %>%
  flextable::width(j="Date of Survey", width=1.1) %>%
  flextable::width(j=c(4,5,6,7,8), width = 0.8) %>%
  flextable::width(j=c(1), width = 1.7) %>%
  flextable::font(fontname="Nunito Sans", part="all") %>%
  flextable::fontsize(size=11) %>%
  flextable::line_spacing(space=1) %>%
  flextable::padding(padding.top = 0.8, padding.bottom = 0.8)

# # Multiple tables using kable
# for (b in unique(tabl$sub_basin)) {
#   tbl <- knitr::kable(tabl[tabl$sub_basin == b, c(2:8)], caption = b)
#   print(tbl)
# }
#knitr::kable(tabl, caption = "Caption")

```
